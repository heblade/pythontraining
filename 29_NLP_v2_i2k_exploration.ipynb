{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enIBIlWsIlpg"
   },
   "source": [
    "References\n",
    "\n",
    "https://www.kaggle.com/akshay235/bert-implementation-on-ner-corpus/notebook\n",
    "\n",
    "https://androidkt.com/name-entity-recognition-with-bert-in-tensorflow/\n",
    "\n",
    "https://colab.research.google.com/drive/1ptxQIRWIHH7sMO097KQeih1nSnrofz7g\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOe93EmhFc9V"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sFtIaWwAqRWO",
    "outputId": "42eccff0-72a5-4b4e-cd36-a551370f04f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cuda device:  1\n",
      "name of cuda device:  Quadro P1000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"num of cuda device: \", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"name of cuda device: \", torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "im1EnFE8y9zE",
    "outputId": "c219de20-d0cd-4094-cdc3-a24e653e6ba7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "NpVHTjHdywqG",
    "outputId": "52f46dfd-8eee-4395-9d51-f10c38efff7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.0.0\n",
      "transformers version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "import transformers\n",
    "print(\"transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ACHDgLPn263P",
    "outputId": "7490d134-e624-422e-838a-cfa1fa8fc85e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import sklearn\n",
    "import seqeval\n",
    "from seqeval import metrics as seq_metrics\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Add\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from transformers import *\n",
    "\n",
    "class FlatScore(object):\n",
    "    \"\"\" Compute sklearn-allowable metric, e.g. average_score, f1_score.\n",
    "    flat_metric = FlatScore('accuracy', 'macro')\n",
    "    flat_metric.score(trues, preds)\n",
    "    \"\"\"\n",
    "    def __init__(self, scorer='accuracy', average='macro', trues=None, preds=None):\n",
    "        self.scorer = scorer\n",
    "        self.scorer_fn = self.get_scorer()\n",
    "        self.average = average\n",
    "        self.ensure_inputs(trues, preds)\n",
    "\n",
    "    def get_scorer(self):\n",
    "        self.scorer = self.scorer if self.scorer.endswith('_score') else self.scorer + '_score'\n",
    "        scorer_fn = getattr(sklearn.metrics, self.scorer)\n",
    "        return scorer_fn\n",
    "\n",
    "    def ensure_inputs(self, trues, preds):\n",
    "        # convert probs & logits into real preds\n",
    "        if trues is None or preds is None:\n",
    "            self.trues, self.preds = None, None\n",
    "        else:\n",
    "            not_int = not (preds.astype(int) == preds).all()\n",
    "            preds = np.argmax(preds, axis=2) if not_int else preds\n",
    "            self.trues = trues.flatten()\n",
    "            self.preds = preds.flatten()\n",
    "\n",
    "    def score(self, scorer=None, average=None, trues=None, preds=None):\n",
    "        if preds is not None:\n",
    "            self.ensure_inputs(trues, preds)\n",
    "        if scorer is not None:\n",
    "            self.scorer = scorer\n",
    "            self.scorer_fn = self.get_scorer()\n",
    "        self.average = average if average else self.average\n",
    "        # compute metric score\n",
    "        if 'average' in self.scorer_fn.__code__.co_varnames:\n",
    "            ans = self.scorer_fn(self.trues, self.preds, average=self.average)\n",
    "        else:\n",
    "            ans = self.scorer_fn(self.trues, self.preds)\n",
    "        return ans\n",
    "\n",
    "    def report(self, trues=None, preds=None):\n",
    "        if preds is not None:\n",
    "            self.ensure_inputs(trues, preds)\n",
    "        report = sklearn.metrics.classification_report(self.trues, self.preds, digits=4)\n",
    "        self.report = report\n",
    "        print(report)\n",
    "\n",
    "def get_column(groups, i):\n",
    "    return [[x[i] for x in group] for group in groups]\n",
    "\n",
    "def ensure_length(targets, labels):\n",
    "    return [[y] * len(x) for x, y in zip(targets, labels)]\n",
    "\n",
    "def tokenize_words_with_tags(words_tags):\n",
    "    \"\"\"\n",
    "    words_tags is tuple of (word, tag1, tag2, ...)\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    tokens = [tokenizer.tokenize(x[0]) for x in words_tags]\n",
    "    ans.append(tokens)\n",
    "    for i in range(len(words_tags[0]) - 1):\n",
    "        ys = ensure_length(tokens, [x[i+1] for x in words_tags])\n",
    "        ys = [x for l in ys for x in l]\n",
    "        ans.append(ys)\n",
    "    ans[0] = [x for l in ans[0] for x in l]\n",
    "    ans = tuple(zip(*ans))\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6XXMbku2sJV"
   },
   "outputs": [],
   "source": [
    "def print_params():\n",
    "    full_data = 'full_data' if include_paragraph and include_table else 'paragraph' if include_paragraph else 'table'\n",
    "    message = \"max_len={max_len}, {full_data}, {data_version}, chunk_data={chunk_data}, \" \\\n",
    "              \"epoch={epoch}, source='{source}', shuffle={shuffle}\"\n",
    "    print(\n",
    "        message.format(\n",
    "            max_len=MAX_LEN, \n",
    "            full_data=full_data, \n",
    "            data_version='data_' + version, \n",
    "            chunk_data=chunk_data,\n",
    "            epoch=evaluator.best_epoch,\n",
    "            source=source,\n",
    "            shuffle=shuffle\n",
    "            )\n",
    "        )\n",
    "\n",
    "def ner_scorer(model, params):\n",
    "    probs = model.predict([params['inputs']], batch_size=params['batch_size'])\n",
    "    preds = probs.argmax(2)\n",
    "    preds2 = [[params['unique_labels'][i] for i in pred] for pred in preds]\n",
    "    trues2 = [[params['unique_labels'][i] for i in true] for true in params['tags']]\n",
    "    out = [(tag[:len(label)], pred[:len(label)]) for label, tag, pred in zip(params['labels'], trues2, preds2)]\n",
    "    trues3, preds3 = zip(*out)\n",
    "    dic = {'val_f1_score': f1_score(trues3, preds3)}\n",
    "    return dic \n",
    "\n",
    "\n",
    "class ModelEvaluator(Callback):\n",
    "    def __init__(self, model, eval_func, eval_params, monitor='val_f1_score',\n",
    "                 patience=1e5, restore_best_weights=True, baseline=None, min_delta=1e-5, \n",
    "                 pathfile='', save_best_only=True, \n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.eval_func = eval_func\n",
    "        self.eval_params = eval_params\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.baseline = baseline\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.pathfile = pathfile\n",
    "        self.save_best_only = save_best_only\n",
    "        #\n",
    "        self.metrics = []\n",
    "        self.wait = 0\n",
    "        self.epoch = 0\n",
    "        self.best_epoch = 0\n",
    "        self.early_stopped_epoch = 0\n",
    "        self.best_score = 0.0\n",
    "        self.best_weights = None\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        print('\\n')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # counting epochs - starting at 1 instead of 0\n",
    "        self.epoch += 1\n",
    "        \n",
    "        # compute evaluation metrics\n",
    "        metrics = self.eval_func(self.model, self.eval_params)\n",
    "        self.metrics.append(metrics)\n",
    "        \n",
    "        # update best results\n",
    "        current = metrics[self.monitor]\n",
    "        if current - self.min_delta > self.best_score:\n",
    "            self.wait = 0\n",
    "            self.best_epoch = self.epoch\n",
    "            self.best_score = current\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:  # trigger early-stopping\n",
    "                self.early_stopped_epoch = self.epoch\n",
    "                self.model.stop_training = True\n",
    "        \n",
    "        # save weights at every epoch, if save_best_only=False\n",
    "        if self.pathfile and not self.save_best_only:\n",
    "            # TODO: assert pathfile is formattable like 'weights_{epoch:02d}_{val_loss:.4f}.hdf5'\n",
    "            pathfile = self.pathfile.format(epoch=self.epoch, **metrics)\n",
    "            self.model.save_weights(pathfile)\n",
    "        \n",
    "        print()\n",
    "        print('%s: %.4f' % (self.monitor, current))\n",
    "    \n",
    "    def on_train_end(self, epoch=None, logs=None):\n",
    "        # must run code in the exact sequence below:\n",
    "        if self.pathfile and self.save_best_only and not self.restore_best_weights:\n",
    "            if self.best_epoch < self.epoch:\n",
    "                last_weights = self.model.get_weights()\n",
    "        \n",
    "        if self.pathfile and self.save_best_only or self.restore_best_weights:\n",
    "            if self.best_epoch < self.epoch:\n",
    "                self.model.set_weights(self.best_weights)\n",
    "        \n",
    "        if self.pathfile and self.save_best_only:\n",
    "            pathfile = self.pathfile.format(epoch=self.best_epoch, **self.metrics[self.best_epoch - 1])\n",
    "            self.model.save_weights(pathfile)\n",
    "        \n",
    "        if self.pathfile and self.save_best_only and not self.restore_best_weights:\n",
    "            if self.best_epoch < self.epoch:\n",
    "                self.model.set_weights(last_weights)\n",
    "        \n",
    "        # print messages\n",
    "        print('\\n')\n",
    "        if self.early_stopped_epoch:  # early-stopped\n",
    "            print('early stopped at Epoch %d' % (self.early_stopped_epoch))\n",
    "        \n",
    "        print(\"Epoch %d gives the best '%s' of %0.4f\" % (self.best_epoch, self.monitor, self.best_score))\n",
    "        \n",
    "        if self.restore_best_weights and self.best_epoch < self.epoch: \n",
    "            print('Restoring model weights from Epoch %d' % (self.best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4sC9uSe5dtp"
   },
   "outputs": [],
   "source": [
    "def chunkup(lst, max_len=200, overlap=30):\n",
    "    if len(lst) <= max_len:\n",
    "        lsts = [lst]\n",
    "    else:\n",
    "        lsts = []\n",
    "        start_idx = 0\n",
    "        while start_idx + overlap <= len(lst):\n",
    "            lsts.append(lst[start_idx:start_idx + max_len])\n",
    "            start_idx += max_len - overlap\n",
    "    return lsts\n",
    "\n",
    "    xdat = pd.DataFrame()\n",
    "    for i in range(len(sdat)):\n",
    "        row = sdat.iloc[i]\n",
    "        groups = chunkup(row['group'], max_len=MAX_LEN, overlap=overlap)\n",
    "        is_tag = np.array([any([x[1] != 'O' for x in group]) for group in groups])\n",
    "        if window_size:\n",
    "            # keep only tags and neighbors\n",
    "            idxes = np.argwhere(is_tag).flatten()\n",
    "            idxes = np.array(list(set(idxes.tolist() + (idxes + window_size).tolist() + (idxes - window_size).tolist())))\n",
    "            idxes = idxes[(0 <= idxes) & (idxes < len(is_tag))]\n",
    "            groups = [groups[i] for i in idxes]\n",
    "        # create save-worthy columns\n",
    "        tdat = pd.DataFrame()\n",
    "        filename = row['file_name']\n",
    "        tdat['file_name'] = np.repeat(filename, len(groups))\n",
    "        tdat['file_id'] = i\n",
    "        tdat['group'] = groups\n",
    "        tdat['is_tag'] = [is_tag[i] for i in idxes]\n",
    "        # combine iterations\n",
    "        xdat = pd.concat([xdat, tdat], axis=0)\n",
    "    xdat.index = range(len(xdat))\n",
    "    return xdat\n",
    "\n",
    "\n",
    "def create_inputs(groups, labels, is_idx=None, chunk_data=True, MAX_LEN=200, overlap=0, pad_separate=False):\n",
    "    \n",
    "    groups = groups[is_idx] if is_idx is not None else groups\n",
    "    labels = labels[is_idx] if is_idx is not None else labels\n",
    "    \n",
    "    if chunk_data:\n",
    "        out = [chunkup(x, max_len=MAX_LEN, overlap=overlap) for x in groups]\n",
    "        groups = [x for lst in out for x in lst]\n",
    "        out = [chunkup(x, max_len=MAX_LEN, overlap=overlap) for x in labels]\n",
    "        labels = [x for lst in out for x in lst]\n",
    "\n",
    "    inputs = pad_sequences([[tokenizer.convert_tokens_to_ids(x) for x in doc] for doc in groups],\n",
    "                              maxlen=MAX_LEN, value=0, padding=\"post\", truncating=\"post\", dtype='int32')\n",
    "    masks = (inputs != tokenizer.pad_token_id).astype(np.int32)\n",
    "\n",
    "    if pad_separate:\n",
    "        tags = pad_sequences([[lab2idx.get(x) for x in tag] for tag in labels],\n",
    "                                maxlen=MAX_LEN, value=lab2idx[\"<pad>\"], padding=\"post\", truncating=\"post\", dtype=\"int32\")\n",
    "    else:\n",
    "        tags = pad_sequences([[lab2idx.get(x) for x in tag] for tag in labels],\n",
    "                                maxlen=MAX_LEN, value=lab2idx[\"O\"], padding=\"post\", truncating=\"post\", dtype=\"int32\")\n",
    "    return (inputs, masks, labels, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "JkL_IIrVrcjW",
    "outputId": "1c13e535-e3d3-442d-db9e-5505aea3f3a2"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bz_2oXUO70A4"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f31fd09a08624689a911c81114c5e2fe",
      "42249e2c7ebe4a7991fa45cacb0e4142",
      "a3970781a311470c9cd6745fdc24b0ba",
      "ff9f3419d8d64f9d85c3d78dca5ca1ee",
      "b26c64e1f58f477890c7d14bdb4136e6",
      "ed2a8f60d59744e2a9e7397cf8f3e298",
      "886b53c6476041d38d9cbc9a700c1c40",
      "e9e0e8432805434189265922ab8df53e"
     ]
    },
    "colab_type": "code",
    "id": "HgNfYQoKhTZM",
    "outputId": "0d69ecfb-f75c-4809-8cbc-4b1ab76e20b1"
   },
   "outputs": [],
   "source": [
    "# TODO: use cased version\n",
    "model_fullname = 'distilbert-base-uncased'\n",
    "lower = model_fullname.endswith('-uncased')\n",
    "BertishTokenizer = DistilBertTokenizer\n",
    "BertishConfig = DistilBertConfig\n",
    "BertishModel = TFDistilBertModel\n",
    "BertishClassifier = TFDistilBertForTokenClassification\n",
    "\n",
    "tokenizer = BertishTokenizer.from_pretrained(model_fullname, do_lower_case=lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTp0M0LAxSeJ"
   },
   "source": [
    "### Chicago Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Do09txRGPCyI",
    "outputId": "389ee5fe-195f-4118-a9e5-5ed7696459d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data file name: 0       173942162.htm\n",
      "1       173942162.htm\n",
      "2       173942162.htm\n",
      "3       173942162.htm\n",
      "4       173942162.htm\n",
      "            ...      \n",
      "7502    223852392.htm\n",
      "7503    223852392.htm\n",
      "7504    223852392.htm\n",
      "7505    223852392.htm\n",
      "7506    223852392.htm\n",
      "Name: file_name, Length: 7507, dtype: object\n",
      "full_data shape: (7507, 7)\n"
     ]
    }
   ],
   "source": [
    "shuffle = False # if False, training on doc-level; otherwise block-level\n",
    "chunk_data = True\n",
    "\n",
    "include_paragraph = True\n",
    "include_table = True\n",
    "\n",
    "source = 'can'\n",
    "version = 'v0'\n",
    "\n",
    "path = \"./datasets/\"\n",
    "file = 'i2k_' + source + '_' + version + '.pickle'\n",
    "with open(path+file, 'rb') as f:\n",
    "    sdat = joblib.load(f)\n",
    "print('full_data file name:', sdat.file_name)\n",
    "print(\"full_data shape:\", sdat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "      <th>is_tag</th>\n",
       "      <th>is_table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((mclean, O), (asset, O), (management, O), (lt...</td>\n",
       "      <td>[McLEAN ASSET MANAGEMENT LTD., \\nFUND FACTS\\nJ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(([PAD], O), ([PAD], O), (this, O), (document,...</td>\n",
       "      <td>[\\n\\nThis document contains key information yo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>((what, O), (does, O), (the, O), (fund, O), (i...</td>\n",
       "      <td>[What does the fund invest in?, ROMC Trust's i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(([PAD], O), ([PAD], O), ([PAD], O), (top, O),...</td>\n",
       "      <td>[\\n\\n\\nTop 10 Investments (April 30, 2018)\\n\\n...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>(([PAD], O), ([PAD], O), ([PAD], O), (investme...</td>\n",
       "      <td>[\\n\\n\\nInvestment Mix (April 30, 2018)\\nTechno...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>(([PAD], O), (how, O), (risky, O), (is, O), (i...</td>\n",
       "      <td>[\\nHow risky is it?\\nThe value of the fund can...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>((the, O), (following, O), (tables, O), (show,...</td>\n",
       "      <td>[The following tables show the fees and expens...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>(([PAD], O), (1, O), (., O), (sales, O), (char...</td>\n",
       "      <td>[\\n1., Sales Charges, There are no sales charg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>((2, O), (., O), (fund, O), (expenses, O), (yo...</td>\n",
       "      <td>[2. Fund expenses, You don't pay these expense...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>173942162.htm</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>(([PAD], O), (fee, O), (for, O), (service, O),...</td>\n",
       "      <td>[\\nFee for Service, \\nSwitch Fee]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  file_id  block_id  \\\n",
       "0  173942162.htm        0         0   \n",
       "1  173942162.htm        0         1   \n",
       "2  173942162.htm        0         2   \n",
       "3  173942162.htm        0         4   \n",
       "4  173942162.htm        0         5   \n",
       "5  173942162.htm        0         6   \n",
       "6  173942162.htm        0        21   \n",
       "7  173942162.htm        0        22   \n",
       "8  173942162.htm        0        23   \n",
       "9  173942162.htm        0        24   \n",
       "\n",
       "                                               group  \\\n",
       "0  ((mclean, O), (asset, O), (management, O), (lt...   \n",
       "1  (([PAD], O), ([PAD], O), (this, O), (document,...   \n",
       "2  ((what, O), (does, O), (the, O), (fund, O), (i...   \n",
       "3  (([PAD], O), ([PAD], O), ([PAD], O), (top, O),...   \n",
       "4  (([PAD], O), ([PAD], O), ([PAD], O), (investme...   \n",
       "5  (([PAD], O), (how, O), (risky, O), (is, O), (i...   \n",
       "6  ((the, O), (following, O), (tables, O), (show,...   \n",
       "7  (([PAD], O), (1, O), (., O), (sales, O), (char...   \n",
       "8  ((2, O), (., O), (fund, O), (expenses, O), (yo...   \n",
       "9  (([PAD], O), (fee, O), (for, O), (service, O),...   \n",
       "\n",
       "                                                text  is_tag  is_table  \n",
       "0  [McLEAN ASSET MANAGEMENT LTD., \\nFUND FACTS\\nJ...    True     False  \n",
       "1  [\\n\\nThis document contains key information yo...    True      True  \n",
       "2  [What does the fund invest in?, ROMC Trust's i...   False     False  \n",
       "3  [\\n\\n\\nTop 10 Investments (April 30, 2018)\\n\\n...   False      True  \n",
       "4  [\\n\\n\\nInvestment Mix (April 30, 2018)\\nTechno...    True      True  \n",
       "5  [\\nHow risky is it?\\nThe value of the fund can...   False     False  \n",
       "6  [The following tables show the fees and expens...   False     False  \n",
       "7  [\\n1., Sales Charges, There are no sales charg...    True     False  \n",
       "8  [2. Fund expenses, You don't pay these expense...   False     False  \n",
       "9                  [\\nFee for Service, \\nSwitch Fee]   False     False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8jygD9V7PaT0",
    "outputId": "74b17f19-9f11-4aa5-b29c-b6566c294da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6756, 751)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not shuffle:\n",
    "    tr_files, val_files = train_test_split(sdat.file_name, random_state=2018, test_size=0.1, shuffle=shuffle)\n",
    "\n",
    "    # known = ['221794582.htm', '220021854.htm', '218286484.htm', '216588855.htm', '214893347.htm']\n",
    "    # unkwn = ['222695709.htm', '222695715.htm', '222828866.htm', '223830364.htm', '223852392.htm']\n",
    "    # val_files = known + unkwn\n",
    "    # tr_files = list(set(sdat.file_name).difference(val_files))\n",
    "\n",
    "len(tr_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "37RgTGZxINAi",
    "outputId": "2bfbf56b-8f85-44ee-a170-5b7e198880a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunked-up train data shape: (3333, 4)\n",
      "chunked-up valid data shape: (400, 4)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 200\n",
    "overlap = 30\n",
    "\n",
    "tr_dat = chunkup_data(sdat[sdat['file_name'].isin(tr_files)], MAX_LEN, overlap=overlap, window_size=1)\n",
    "val_dat = chunkup_data(sdat[sdat['file_name'].isin(val_files)], MAX_LEN, overlap=0, window_size=1)\n",
    "print(\"chunked-up train data shape:\", tr_dat.shape)\n",
    "print(\"chunked-up valid data shape:\", val_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0H4YGQlUTt_R",
    "outputId": "5d0524bc-cefa-442c-f635-73400d6c1674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 17\n"
     ]
    }
   ],
   "source": [
    "pad_separate = False\n",
    "\n",
    "labels = np.array(get_column(tr_dat['group'], 1) + get_column(val_dat['group'], 1))\n",
    "unique_labels = sorted(set([x for label in labels for x in label]))\n",
    "unique_labels.remove('O')\n",
    "if pad_separate:\n",
    "    unique_labels = ['<pad>', 'O'] + sorted(unique_labels)\n",
    "else:\n",
    "    unique_labels = ['O'] + sorted(unique_labels)\n",
    "\n",
    "lab2idx = {t: i for i, t in enumerate(unique_labels)}\n",
    "print(\"number of labels:\", len(lab2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "19Q7X-DsUvUl",
    "outputId": "c2b3f0a9-72a9-43a2-a66d-c3c4aef18395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (3333, 200)\n",
      "valid data: (400, 200)\n"
     ]
    }
   ],
   "source": [
    "groups = np.array(get_column(tr_dat['group'], 0))\n",
    "labels = np.array(get_column(tr_dat['group'], 1))\n",
    "tr_inputs, tr_masks, tr_labels, tr_tags = create_inputs(groups, labels, None, \n",
    "                                                        False, MAX_LEN, 30, \n",
    "                                                        pad_separate)\n",
    "groups = np.array(get_column(val_dat['group'], 0))\n",
    "labels = np.array(get_column(val_dat['group'], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "print(\"train data:\", tr_inputs.shape) \n",
    "print(\"valid data:\", val_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p64W6_6e4Oqs"
   },
   "source": [
    "#### known vs. unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "unJp4Mq963FP",
    "outputId": "e7b4f26f-eecf-4df5-db4e-19dfe519f5b8"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "groups = np.array(get_column(tr_dat['group'], 0))\n",
    "labels = np.array(get_column(tr_dat['group'], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "JzIT0p0V66Y_",
    "outputId": "b2f426a3-6789-49e3-8690-2bb55287062a"
   },
   "outputs": [],
   "source": [
    "# validation data\n",
    "groups = np.array(get_column(val_dat['group'], 0))\n",
    "labels = np.array(get_column(val_dat['group'], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "p7rCKcFv7__L",
    "outputId": "0288e0c1-f8d9-44da-cc49-75f098de1146"
   },
   "outputs": [],
   "source": [
    "# unknown valiation data\n",
    "is_idx = val_dat['file_name'].isin(unkwn)\n",
    "\n",
    "groups = np.array(get_column(val_dat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(val_dat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "z8BJzFSH8FN5",
    "outputId": "a126cf61-dfba-40d2-b653-1096e48e47e0"
   },
   "outputs": [],
   "source": [
    "# known valiation data\n",
    "is_idx = val_dat['file_name'].isin(known)\n",
    "\n",
    "groups = np.array(get_column(val_dat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(val_dat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "P9mlZQBK8IyZ",
    "outputId": "9699c1f8-4866-41b7-ce11-82f14e24511e"
   },
   "outputs": [],
   "source": [
    "# well-known validation data\n",
    "is_idx = val_dat['file_name'].isin(known[:2])\n",
    "\n",
    "groups = np.array(get_column(val_dat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(val_dat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "NOmmDgwDbRHO",
    "outputId": "86284bb7-443d-481d-e300-48aa1462f487"
   },
   "outputs": [],
   "source": [
    "# known-somewhat validation data\n",
    "is_idx = val_dat['file_name'].isin(known[2:])\n",
    "\n",
    "groups = np.array(get_column(val_dat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(val_dat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            False, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bHc4QyWH0Sb2",
    "outputId": "3d171ebe-2ee0-4c77-cedc-90b434fc718f"
   },
   "outputs": [],
   "source": [
    "# output training and validation files\n",
    "# trn_files = xdat.loc[is_train, 'file_name'].unique()\n",
    "# val_files = xdat.loc[is_valid, 'file_name'].unique()\n",
    "# len(trn_files), len(val_files)\n",
    "# trn_files = pd.DataFrame([trn_files, np.repeat(1, len(trn_files))], index=['filename', 'is_training']).T\n",
    "# val_files = pd.DataFrame([val_files, np.repeat(0, len(val_files))], index=['filename', 'is_training']).T\n",
    "# all_files = pd.concat([trn_files, val_files], axis=0, ignore_index=True)\n",
    "# all_files.to_csv(path + 'train_val_split.cvs', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0Hi4uuI2tBa"
   },
   "source": [
    "### Shenzhen Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "H6E_PXjm0BcV",
    "outputId": "5eaf3114-6c14-419d-de62-8202c99c1900"
   },
   "outputs": [],
   "source": [
    "shuffle = False # if False, training on doc-level; otherwise block-level\n",
    "override = False \n",
    "\n",
    "include_paragraph = True\n",
    "include_table = True\n",
    "\n",
    "source = 'uk'\n",
    "version = 'v2'\n",
    "path = \"/content/drive/My Drive/Colab Notebooks/datasets/\"\n",
    "\n",
    "if (not shuffle) and override:  # shuffle/split docs by assignment\n",
    "    file = 'i2k_' + source + '_' + version + '.pickle'\n",
    "    with open(path+file, 'rb') as f:\n",
    "        xdat = joblib.load(f)\n",
    "    print(\"full_data    shape:\", xdat.shape)\n",
    "    \n",
    "    # val_files = ['221794582.htm', '221902556.htm', '222466057.htm', '222466194.htm', '222466913.htm',\n",
    "    #             '222695709.htm', '222695715.htm', '222828866.htm', '223830364.htm', '223852392.htm']\n",
    "\n",
    "    known = ['221794582.htm', '220021854.htm', '218286484.htm', '216588855.htm', '214893347.htm']\n",
    "    unkwn = ['222695709.htm', '222695715.htm', '222828866.htm', '223830364.htm', '223852392.htm']\n",
    "    val_files = known + unkwn\n",
    "    \n",
    "    is_valid = xdat['file_name'].isin(val_files)\n",
    "    is_train = ~is_valid\n",
    "else:\n",
    "    file = 'i2k_' + source + '_' + 'v2' + '.pickle'\n",
    "    with open(path+file, 'rb') as f:\n",
    "        xdat = joblib.load(f)\n",
    "    print(\"full_data    shape:\", xdat.shape)\n",
    "\n",
    "    if include_paragraph and not include_table:\n",
    "        xdat = xdat[~xdat['is_table']]\n",
    "    elif not include_paragraph and include_table:\n",
    "        xdat = xdat[xdat['is_table']]\n",
    "    print(\"current_data shape:\", xdat.shape)\n",
    "\n",
    "    if version == 'v2':\n",
    "        tr_idx, val_idx = train_test_split(xdat.index, random_state=2018, test_size=0.1, shuffle=shuffle)\n",
    "        is_train = xdat.index.isin(tr_idx)\n",
    "        is_valid = xdat.index.isin(val_idx)\n",
    "\n",
    "    if version == 'v3':  # expand v2 to v3\n",
    "        tdat = xdat\n",
    "        version = 'v3'\n",
    "        file = 'i2k_' + source + '_' + 'v3' + '.pickle'\n",
    "        with open(path+file, 'rb') as f:\n",
    "            xdat = joblib.load(f)\n",
    "        print(\"full_data    shape:\", xdat.shape)\n",
    "        \n",
    "        tr_idx, val_idx = train_test_split(tdat.index, random_state=2018, test_size=0.1, shuffle=shuffle)\n",
    "        is_train = xdat['rid'].isin(tr_idx)\n",
    "        is_valid = xdat['rid'].isin(val_idx)\n",
    "\n",
    "print(\"training data:\", is_train.sum())\n",
    "print(\"test     data:\",  is_valid.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XaMlMZW75bFu",
    "outputId": "99f8d9d8-43a4-462a-88f5-c74d3165f59b"
   },
   "outputs": [],
   "source": [
    "groups = np.array(get_column(xdat['group'], 0))\n",
    "labels = np.array(get_column(xdat['group'], 1))\n",
    "\n",
    "pad_separate = False\n",
    "unique_labels = sorted(set([x for label in labels for x in label]))\n",
    "unique_labels.remove('O')\n",
    "if pad_separate:\n",
    "    unique_labels = ['<pad>', 'O'] + sorted(unique_labels)\n",
    "else:\n",
    "    unique_labels = ['O'] + sorted(unique_labels)\n",
    "\n",
    "lab2idx = {t: i for i, t in enumerate(unique_labels)}\n",
    "print(\"number of labels:\", len(lab2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "3hSkRbdOaRf_",
    "outputId": "80c891b0-016d-4fbb-96ff-f7c6f2224783"
   },
   "outputs": [],
   "source": [
    "chunk_data = True\n",
    "MAX_LEN = 200\n",
    "overlap = 30\n",
    "\n",
    "tr_inputs, tr_masks, tr_labels, tr_tags = create_inputs(groups, labels, is_train, \n",
    "                                                        chunk_data, MAX_LEN, overlap, \n",
    "                                                        pad_separate)\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, is_valid, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "print(\"train, test before chunking:\", len(groups[is_train]), len(groups[is_valid]))\n",
    "print(\"train, test after  chunking:\", len(tr_inputs), len(val_inputs))\n",
    "print(\"training cases: \", tr_inputs.shape)\n",
    "print(\"validation cases:\", val_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yh0sHhe4ba_"
   },
   "source": [
    "#### known vs. unknown data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0APrJgVa4F_P"
   },
   "source": [
    "##### v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "lJ-OnFUkvLEV",
    "outputId": "ec8b5bbf-9ed0-4083-a9f2-cc69a0aba018"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "is_idx = xdat['file_name'].isin(set(xdat['file_name']).difference(val_files))\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "yoieOrjxvNoz",
    "outputId": "798a9967-826f-43de-d9ab-3436eb2e85b1"
   },
   "outputs": [],
   "source": [
    "# validation data\n",
    "is_idx = xdat['file_name'].isin(val_files)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "La75Qzm0vSK-",
    "outputId": "da3f4127-bd21-4308-a558-3a986ce3f53c"
   },
   "outputs": [],
   "source": [
    "# unknown validation data\n",
    "is_idx = xdat['file_name'].isin(unkwn)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "YmIfclOfvLBN",
    "outputId": "b0dfe7ea-d931-49a3-d0d1-e7921373bcc4"
   },
   "outputs": [],
   "source": [
    "# known validation data\n",
    "is_idx = xdat['file_name'].isin(known)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "nDYUbg9nrhpu",
    "outputId": "e018c773-3e5a-4682-f17d-7cf575304f3c"
   },
   "outputs": [],
   "source": [
    "# known-well validation data\n",
    "is_idx = xdat['file_name'].isin(known[:2])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "AQQTmJxMrhmc",
    "outputId": "fb5f98da-e5a3-4b53-e685-4587c9b7685d"
   },
   "outputs": [],
   "source": [
    "# known-somewhat validation data\n",
    "is_idx = xdat['file_name'].isin(known[2:])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zKkPY063cEX"
   },
   "source": [
    "##### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "ZPefesSGWT1q",
    "outputId": "9a08bd86-db15-4f13-f64b-4dcee3095c4b"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "is_idx = xdat['file_name'].isin(set(xdat['file_name']).difference(val_files))\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "2B8bSqTIWWkl",
    "outputId": "e9d8ccd1-15f2-4a39-abd7-287960e27b0f"
   },
   "outputs": [],
   "source": [
    "# validation data\n",
    "is_idx = xdat['file_name'].isin(val_files)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "fxg6cUMgWYzf",
    "outputId": "25a7139c-67df-41e4-87f1-0225ab76e077"
   },
   "outputs": [],
   "source": [
    "# unknown validation data\n",
    "is_idx = xdat['file_name'].isin(unkwn)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "ufIPCmEaWbJT",
    "outputId": "585c29ca-ca06-4105-ff8f-b52daf7436e1"
   },
   "outputs": [],
   "source": [
    "# known validation data\n",
    "is_idx = xdat['file_name'].isin(known)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "WBFKL6kAWdgD",
    "outputId": "18a6296e-7010-467e-e950-0b2b32ab1aae"
   },
   "outputs": [],
   "source": [
    "# known-well validation data\n",
    "is_idx = xdat['file_name'].isin(known[:2])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "fQZ7kqLcWffB",
    "outputId": "2733ace2-1fce-46e3-cacf-f5d6a70351e0"
   },
   "outputs": [],
   "source": [
    "# known-somewhat validation data\n",
    "is_idx = xdat['file_name'].isin(known[2:])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU2-W_zP3226"
   },
   "source": [
    "##### v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "7fWf8gFf4D12",
    "outputId": "9a08bd86-db15-4f13-f64b-4dcee3095c4b"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "is_idx = xdat['file_name'].isin(set(xdat['file_name']).difference(val_files))\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "rBQ6Uhwd4D18",
    "outputId": "3be76b79-3dee-4cbe-93d6-a17679e68814"
   },
   "outputs": [],
   "source": [
    "# validation data\n",
    "is_idx = xdat['file_name'].isin(val_files)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "4KzP8a_G4D1-",
    "outputId": "0f7ede59-a65a-4acb-a712-4aa338048887"
   },
   "outputs": [],
   "source": [
    "# unknown validation data\n",
    "is_idx = xdat['file_name'].isin(unkwn)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "iOoMQOOR4D2C",
    "outputId": "93a728d0-f57a-40c7-d277-c058dadfe624"
   },
   "outputs": [],
   "source": [
    "# known validation data\n",
    "is_idx = xdat['file_name'].isin(known)\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "ejkjvkhg4D2F",
    "outputId": "0b4b4f63-86af-4fbc-a772-47d8675612a4"
   },
   "outputs": [],
   "source": [
    "# known-well validation data\n",
    "is_idx = xdat['file_name'].isin(known[:2])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "DozXy1Fy4D2H",
    "outputId": "0380d61f-538f-4856-8611-07d9edbc5fb6"
   },
   "outputs": [],
   "source": [
    "# known-somewhat validation data\n",
    "is_idx = xdat['file_name'].isin(known[2:])\n",
    "\n",
    "groups = np.array(get_column(xdat['group'][is_idx], 0))\n",
    "labels = np.array(get_column(xdat['group'][is_idx], 1))\n",
    "val_inputs, val_masks, val_labels, val_tags = create_inputs(groups, labels, None, \n",
    "                                                            chunk_data, MAX_LEN, 0, \n",
    "                                                            pad_separate)\n",
    "\n",
    "val_ntop = len(val_inputs)\n",
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print_params()\n",
    "print(f1_score(trues3, preds3), '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8DcO1ZhqyGa"
   },
   "source": [
    "## Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiWvVBvttRGn"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOrIMHv14Wb-"
   },
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJHzqjHl0skz"
   },
   "outputs": [],
   "source": [
    "num_classes = len(lab2idx)\n",
    "customize = True\n",
    "\n",
    "# build model\n",
    "if customize:\n",
    "    inputs = Input(shape=(MAX_LEN,), dtype=tf.int32, name='inputs')\n",
    "    layer = BertishModel.from_pretrained(model_fullname)\n",
    "    layer = layer([inputs])\n",
    "    layer = Lambda(lambda x: x[0])(layer)\n",
    "    layer = Dropout(rate=0.2)(layer)\n",
    "    output = Dense(num_classes, activation='softmax')(layer)\n",
    "    model = Model([inputs], output)\n",
    "else:\n",
    "    config = BertishConfig.from_pretrained(model_fullname, \n",
    "                                           attention_dropout=0.1,  # somehow matters\n",
    "                                           dropout=0.1,  # matters greatly\n",
    "                                           num_labels=num_classes)\n",
    "    model = BertishClassifier.from_pretrained(model_fullname, config=config)\n",
    "    model.layers[-1].activation = tf.keras.activations.softmax\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00003)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBxFgLqgtS7j"
   },
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5iWp57IWhUNA",
    "outputId": "514d0db3-5f91-400b-f293-84f0ef55e6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len=200, full_data, data_v0, chunk_data=True, epoch=0, source='can', shuffle=False\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# bs = 16\n",
    "bs = 4\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': bs,\n",
    "    'inputs': val_inputs[:val_ntop],\n",
    "    'tags': val_tags[:val_ntop],\n",
    "    'labels': val_labels[:val_ntop],\n",
    "    'unique_labels': unique_labels\n",
    "}\n",
    "\n",
    "pathfile = ''\n",
    "# pathfile = path + 'weights_best_model.hdf5'\n",
    "# pathfile = path + 'weights_{epoch:02d}_{val_f1_score:.4f}.hdf5'\n",
    "evaluator = ModelEvaluator(model, eval_func=ner_scorer, eval_params=eval_params, monitor='val_f1_score',\n",
    "                           patience=5, restore_best_weights=True,\n",
    "                           pathfile=pathfile, save_best_only=True)\n",
    "\n",
    "print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "Hzbc2G5rcnnX",
    "outputId": "b6e4df13-3276-4b49-ccd3-56ce40f7a0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3333 samples, validate on 400 samples\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9841\n",
      "val_f1_score: 0.6717\n",
      "3333/3333 [==============================] - 318s 95ms/sample - loss: 0.0626 - accuracy: 0.9841 - val_loss: 0.0461 - val_accuracy: 0.9873\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9952\n",
      "val_f1_score: 0.7691\n",
      "3333/3333 [==============================] - 310s 93ms/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0475 - val_accuracy: 0.9886\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "val_f1_score: 0.7249\n",
      "3333/3333 [==============================] - 310s 93ms/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0264 - val_accuracy: 0.9900\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
      "val_f1_score: 0.8034\n",
      "3333/3333 [==============================] - 311s 93ms/sample - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0454 - val_accuracy: 0.9897\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9974\n",
      "val_f1_score: 0.7487\n",
      "3333/3333 [==============================] - 311s 93ms/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0401 - val_accuracy: 0.9881\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9979\n",
      "val_f1_score: 0.7415\n",
      "3333/3333 [==============================] - 310s 93ms/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.9912\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
      "val_f1_score: 0.7571\n",
      "3333/3333 [==============================] - 311s 93ms/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0384 - val_accuracy: 0.9897\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n",
      "val_f1_score: 0.7997\n",
      "3333/3333 [==============================] - 310s 93ms/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0531 - val_accuracy: 0.9890\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "3332/3333 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "val_f1_score: 0.7908\n",
      "3333/3333 [==============================] - 310s 93ms/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0505 - val_accuracy: 0.9882\n",
      "\n",
      "\n",
      "early stopped at Epoch 9\n",
      "Epoch 4 gives the best 'val_f1_score' of 0.8034\n",
      "Restoring model weights from Epoch 4\n",
      "max_len=200, full_data, data_v0, chunk_data=True, epoch=4, source='can', shuffle=False\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    callbacks=[evaluator],\n",
    "                    epochs=100,\n",
    "                    verbose=1)\n",
    "\n",
    "print_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eRGWxaneJXFG",
    "outputId": "c518fb81-d997-4125-9b66-e9cb8246bc31"
   },
   "outputs": [],
   "source": [
    "path + source + '_' + version + '_unshuffle.h5'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJ6e_U7m-sOl"
   },
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model:\n",
    "    model.save_weights(path + source + '_' + version + '_unshuffle.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "Fbc58drICIdV",
    "outputId": "7cade92c-863a-4631-ffac-dc1f1a3cd564"
   },
   "outputs": [],
   "source": [
    "[x for x in os.listdir(path) if x.endswith('h5') or x.endswith('hdf5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqCRtFQxAsJC"
   },
   "outputs": [],
   "source": [
    "load_model = True\n",
    "if load_model:\n",
    "    model.load_weights(path + source + '_' + version + '_unshuffle.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rgcX6aV7zkwN",
    "outputId": "cc0b11e7-600e-4399-abdd-8868416f8150"
   },
   "outputs": [],
   "source": [
    "clean_models = False\n",
    "if clean_models:\n",
    "    [os.remove(path + x) for x in os.listdir(path) if x.endswith('h5') or x.endswith('hdf5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vu8ksFOcowb"
   },
   "source": [
    "source = CAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Tg6v7LzYAFXm",
    "outputId": "e18ab008-1738-44c2-82ef-3cdf5be49d2f"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "bs = 16\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': bs,\n",
    "    'inputs': val_inputs[:val_ntop],\n",
    "    'tags': val_tags[:val_ntop],\n",
    "    'labels': val_labels[:val_ntop],\n",
    "    'unique_labels': unique_labels\n",
    "}\n",
    "\n",
    "pathfile = ''\n",
    "# pathfile = path + 'weights_best_model.hdf5'\n",
    "# pathfile = path + 'weights_{epoch:02d}_{val_f1_score:.4f}.hdf5'\n",
    "evaluator = ModelEvaluator(model, eval_func=ner_scorer, eval_params=eval_params, monitor='val_f1_score',\n",
    "                           patience=5, restore_best_weights=True,\n",
    "                           pathfile=pathfile, save_best_only=True)\n",
    "\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    callbacks=[evaluator],\n",
    "                    epochs=100,\n",
    "                    verbose=1)\n",
    "\n",
    "print_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEkC5kwBc7Yd"
   },
   "source": [
    "source = UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "qyOo6Wl1MC5u",
    "outputId": "d6f450b4-1de4-4812-d260-d1417ff01ebd"
   },
   "outputs": [],
   "source": [
    "# max_len=40, full_labels, bert, full_data\n",
    "gc.collect()\n",
    "bs = 16\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQQwJOmPc9C-"
   },
   "source": [
    "source = US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "9zs3-FwJ7aXH",
    "outputId": "f95956df-4742-4855-ff95-4cacdd2b8ac5"
   },
   "outputs": [],
   "source": [
    "# max_len=80, bert, source='can'\n",
    "gc.collect()\n",
    "bs = 16\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    epochs=3,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3DccUGqtWHi"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHIc9E298Gp8"
   },
   "outputs": [],
   "source": [
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sP-pqXPlxwqV"
   },
   "outputs": [],
   "source": [
    "print(evaluator.best_score)\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7J7NIX5_1d2i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "lf48r7Mc0yMZ",
    "outputId": "9fe51ed4-01b8-4748-f833-b1c752b3aa7b"
   },
   "outputs": [],
   "source": [
    "probs = model.predict([val_inputs[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "print(evaluator.best_score)\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulYTBuHwZBWV"
   },
   "source": [
    "### Model Evaluation - B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H11mH54fZnaL"
   },
   "source": [
    "- compare Chicago vs. SZ versions with chunked-up full data\n",
    "- different chunking strategies with varying max_length and overlap\n",
    "- examine use of varying chunking strategies at each epoch to prevent overfitting\n",
    "- paragraphs vs. tables\n",
    "- remove 'support < 50' from test and/or from training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QjwC0rAZNuG"
   },
   "source": [
    "#### CAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "F-eB81BS4JL-",
    "outputId": "6826cf50-8d66-458e-fdd4-d2818340540a"
   },
   "outputs": [],
   "source": [
    "print_params()  # 10 vs. 10\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "DFluhsBzZqfd",
    "outputId": "fe7a51f4-47cb-4a5f-a286-e5a3c33a9ae2"
   },
   "outputs": [],
   "source": [
    "print_params()  # 10 vs. 10\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "P4FX-bNFoG2l",
    "outputId": "3ef29bcd-b76b-4fc5-8ab6-783155a54e06"
   },
   "outputs": [],
   "source": [
    "print_params()  # 10 vs. 10\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjQR5yGyGtcS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "w2PbDgrZl065",
    "outputId": "47ae6cbd-ff58-4992-965e-23ded38b79a9"
   },
   "outputs": [],
   "source": [
    "print_params()  # 10 vs. 10\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "8VerqpavJPfd",
    "outputId": "59d9955b-aa69-4142-d927-1be661f66fc7"
   },
   "outputs": [],
   "source": [
    "print_params()  # 1 vs. 9\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI4ZtSpZZqoj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M7onGuRZqwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLcDVMfmZqst"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "ta33kIgZP_4-",
    "outputId": "9f2ad2b4-a374-4d4a-c25f-f8a0c5fcc180"
   },
   "outputs": [],
   "source": [
    "print_params()  # 157 sec/epoch\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "5BxyrgPEE8xP",
    "outputId": "5323f8bc-93ea-48b8-9faa-daa7e17bf1d8"
   },
   "outputs": [],
   "source": [
    "print_params()  # 225 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "wF9YeuZTdDwh",
    "outputId": "915bd441-f5ee-4d20-bb34-48d850cb9b77"
   },
   "outputs": [],
   "source": [
    "print_params()  # 225 sec/epoch\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "XUYmP8NsQAMb",
    "outputId": "d6be5e1f-c477-4349-acdc-c9d1473831d5"
   },
   "outputs": [],
   "source": [
    "print_params()  # 171 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "dEgAYD5qg3FV",
    "outputId": "8b5f6b68-9342-451f-ecf7-04e9f2d47a15"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEZG-H-LbXF4"
   },
   "source": [
    "#### UK Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bye4w6dRx0bD",
    "outputId": "cee5520b-8cd5-4803-9d67-58cfc749eb4c"
   },
   "outputs": [],
   "source": [
    "print_params()  # 186 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qdMeJGvow0S6",
    "outputId": "2e1384dd-f700-483b-df59-99f0b3e12c62"
   },
   "outputs": [],
   "source": [
    "print_params()  # natural split\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ov7aNSkpUEaF"
   },
   "outputs": [],
   "source": [
    "print_params()  # natural split\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hQ5dlnax9c0T",
    "outputId": "eea9ec31-71d6-4a95-a75e-e9a5128bbbd5"
   },
   "outputs": [],
   "source": [
    "print_params()  # natural split\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m7WlyEHWZ2Vd",
    "outputId": "3be6729e-2fbc-479b-970e-448761b8b38d"
   },
   "outputs": [],
   "source": [
    "print_params()  # 186 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kkQa0esh8jr5",
    "outputId": "921b6838-83ee-49bd-9e76-d513d44658e6"
   },
   "outputs": [],
   "source": [
    "print_params()  # 285 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fwpOkUEbZ55"
   },
   "source": [
    "#### US Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PpSfkVj1b7fE",
    "outputId": "c29e8e06-75e6-45a0-ad6d-95aaecda1279"
   },
   "outputs": [],
   "source": [
    "print_params()  # 139 (16G) sec/epoch\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wICG12HuG5MW",
    "outputId": "b43d824e-230a-42c9-a729-2231570fa8b6"
   },
   "outputs": [],
   "source": [
    "print_params()  # 142 (16G) sec/epoch 304 (P4)\n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CZcF55cMG4op",
    "outputId": "648e47d9-54d6-4c42-c8fc-4c2ab2d48746"
   },
   "outputs": [],
   "source": [
    "print_params()  # 276 sec/epoch (16G)\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axJkoe3_baa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAdXBm-cDruW"
   },
   "source": [
    "### Model Evaluation - B1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anO5aM9UbKU7"
   },
   "source": [
    "#### CAN Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA818nHEKyTc"
   },
   "source": [
    "##### max_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "-XJCzqA8Jf2f",
    "outputId": "2c29b639-c91d-4d5f-faf8-0cbb3bde5746"
   },
   "outputs": [],
   "source": [
    "print_params() \n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "hKjANw0M_Ed5",
    "outputId": "b00c991f-348a-4f8a-c64b-2c41aa3dd833"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "id": "qxAFnCQPkmaf",
    "outputId": "23491fd5-8dc2-4f43-b1ae-a293e36d5611"
   },
   "outputs": [],
   "source": [
    "# max_len=300, paragraph, data_v2, epoch=4\n",
    "print(f1_score(trues3, preds3))\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "YnCNqtnOFy0W",
    "outputId": "d0ef1f33-764d-4f6f-8974-396418327939"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "pKuWgBcOKmk8",
    "outputId": "8e1cfe72-facb-4185-bf96-de2558de1acc"
   },
   "outputs": [],
   "source": [
    "# max_len=300, table, data_v2, epoch=3\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-Hbz1clK6hf"
   },
   "source": [
    "##### max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "Jy_KahxJg2vd",
    "outputId": "7d58f031-167e-4407-e0f4-9b2f45c5bc32"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "GKeXnuis4cpX",
    "outputId": "5933004b-4687-4dfe-f9b5-c55ff49e9615"
   },
   "outputs": [],
   "source": [
    "print_params() \n",
    "print(evaluator.best_score, '\\n') \n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "atOZke_7qCHe",
    "outputId": "ee704deb-88a1-4b19-ab4d-b81890e95ed8"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "JAI37uNPryBT",
    "outputId": "389a90a0-45e0-4495-bed5-eb188e4bb5d7"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "j39WuljQhpH7",
    "outputId": "705f0d61-4656-46a3-a430-7d54b74e175b"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "lsF_yyT5tL1N",
    "outputId": "b52732c9-80ae-4df9-ddb1-c497199384d6"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "Rz8Snch-dT3u",
    "outputId": "534a315e-00cb-4b8f-ccc2-0b3a7faade1a"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "sG0riBAQTMEN",
    "outputId": "1f84b3e5-268e-4934-937e-8ba661d3cb45"
   },
   "outputs": [],
   "source": [
    "# max_len=200, paragraph, data_v2, epoch=4\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "y3DwlLgzfBxn",
    "outputId": "bb29c83b-02d3-4ec1-f84f-d58cb82b88fd"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHAYf8IcpohH"
   },
   "source": [
    "##### max_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "r8qLbEIZ7N7j",
    "outputId": "ea020c33-28ad-43f2-b6a8-71c8c66611e3"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "MVx8EU0wv9oe",
    "outputId": "c84f3953-98be-4023-cc46-78a7af27eb24"
   },
   "outputs": [],
   "source": [
    "# max_len=120, paragraph, data_v2, epoch=4\n",
    "print(f1_score(trues3, preds3))\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "VW0qkMDWzOsK",
    "outputId": "2b024f61-81f9-4f47-8052-0170c69f6bd6"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "7pvpYeGg4-eZ",
    "outputId": "37a2965e-3525-4be0-b3f5-b1d9a94c3ae5"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "dQtjPj4e0Ih1",
    "outputId": "5a8a733b-6220-4599-e2e2-38b5313cbd5b"
   },
   "outputs": [],
   "source": [
    "# max_len=120, table, data_v2, epoch=7\n",
    "print(f1_score(trues3, preds3))\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FV8FSU4b0KuL"
   },
   "source": [
    "##### max_len = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "Mh97piuTGK3s",
    "outputId": "899d8149-9ea0-4b6f-eefa-2d9aeb9cf425"
   },
   "outputs": [],
   "source": [
    "# max_len=80, full_data, data_v2, epoch=4-6\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "vfjSrxbIxz0B",
    "outputId": "a526780d-6933-4d42-b2b7-8c8e117b0d1d"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "XPBpN1dY0O03",
    "outputId": "b8a0055b-bf42-4334-d2a7-329823049617"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "KDnpivSbGujn",
    "outputId": "628320b4-ac13-4848-ed4c-616511df6f1a"
   },
   "outputs": [],
   "source": [
    "# max_len=80, paragraph, data_v2, epoch=3-4\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "6bB8b6wV0O3i",
    "outputId": "c93707bc-18c7-4608-9114-8dc1ed2e2a57"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8YE9tJ60PvG"
   },
   "source": [
    "##### max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "proCfy0C0O7T",
    "outputId": "0ea8ab9d-f181-4544-fd78-42b327438dcb"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "atL-w9rvfeyW",
    "outputId": "961c5faa-ab9f-49bf-9519-6580fb9875d3"
   },
   "outputs": [],
   "source": [
    "# max_len=50, full_data, data_v2, epoch=3-4\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "18GPVUG4xz3u",
    "outputId": "67515995-c22f-48b2-e693-40e8fbb844f6"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "CtUiIMiHxzxo",
    "outputId": "9745b1dc-b4d7-4e99-f850-a8ebdaef252c"
   },
   "outputs": [],
   "source": [
    "print_params()\n",
    "print(evaluator.best_score, '\\n')\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds); metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr6rJR5RbUNL"
   },
   "source": [
    "#### UK Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6d2-bHoBwi7R",
    "outputId": "bdd6fbc1-e9d3-43cd-a1ac-9b07420780fb"
   },
   "outputs": [],
   "source": [
    "# max_len=120, bert, source='uk'\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdB2MD3CbCLN"
   },
   "source": [
    "#### US Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mQbBiGN0x10k",
    "outputId": "9c28f192-0572-4424-9e0c-00770975be4d"
   },
   "outputs": [],
   "source": [
    "# max_len=120, bert, source='us'\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ehy6fqIl5-03",
    "outputId": "3a438d17-86f0-4a17-ad22-2cd8a47659b5"
   },
   "outputs": [],
   "source": [
    "# max_len=80, bert, source='uk'\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVEQBt3fq88A"
   },
   "source": [
    "### Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8W8DkXhLs98l"
   },
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYS90wkH7d_t"
   },
   "outputs": [],
   "source": [
    "num_classes = len(lab2idx)\n",
    "\n",
    "# build model\n",
    "inputs = Input(shape=(MAX_LEN,), dtype=tf.int32, name='inputs')\n",
    "layer = BertishModel.from_pretrained(model_fullname)\n",
    "layer = layer([inputs])\n",
    "layer = Lambda(lambda x: x[0])(layer)\n",
    "layer = Dropout(rate=0.2)(layer)\n",
    "layer = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                        recurrent_dropout=0.2, dropout=0.2))(layer)\n",
    "layer2 = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                        recurrent_dropout=0.2, dropout=0.2))(layer)\n",
    "layer = Add()([layer, layer2])  # residual connection to the first biLSTM\n",
    "output = Dense(num_classes, activation='softmax')(layer)\n",
    "model = Model([inputs], output)\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00003)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCIFALIXtBGu"
   },
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "eCvphobnqk7d",
    "outputId": "75be70e1-cbdf-4aaa-962e-24b411e52142"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, 10000_data\n",
    "gc.collect()\n",
    "bs = 32\n",
    "tr_ntop = 10000\n",
    "val_ntop = 1000\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "azYl7nhVA5T2",
    "outputId": "1a718fa3-319b-4f94-8338-a871c8db946b"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "gc.collect()\n",
    "bs = 32\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "rDH2VpssHjru",
    "outputId": "c21200a0-28d9-462a-d48d-614337373385"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "gc.collect()\n",
    "bs = 32\n",
    "tr_ntop = len(tr_inputs)\n",
    "val_ntop = len(val_inputs)\n",
    "history = model.fit(x=[tr_inputs[:tr_ntop]], \n",
    "                    y=tr_tags[:tr_ntop], \n",
    "                    validation_data=([val_inputs[:val_ntop]], val_tags[:val_ntop]),\n",
    "                    batch_size=bs,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rR8GuEXBsC7p"
   },
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzAYhqxOFJVR"
   },
   "outputs": [],
   "source": [
    "probs = model.predict([val_inputs[:val_ntop], val_masks[:val_ntop]], batch_size=bs)\n",
    "\n",
    "preds = probs.argmax(2)\n",
    "trues = val_tags[:val_ntop]\n",
    "labes = val_labels[:val_ntop]\n",
    "preds2 = [[unique_labels[i] for i in pred] for pred in preds]\n",
    "trues2 = [[unique_labels[i] for i in true] for true in trues]\n",
    "out = [(t[:len(l)], p[:len(l)]) for l,t,p in zip(labes, trues2, preds2)]\n",
    "trues3, preds3 = zip(*out)\n",
    "\n",
    "if collapse_labels:\n",
    "    # unique_labels = sorted(set(xdat[\"tag\"]))\n",
    "    # unique_labels.remove('O')\n",
    "    # unique_labels = ['O'] + sorted(unique_labels, key=lambda x: x.split('-')[1])\n",
    "    # lab2idx = {t: i for i, t in enumerate(unique_labels)}\n",
    "    lab2collapse = {x: x.split('-')[1] if x.find('-')>=0 else x for x in lab2idx}\n",
    "    trues4 = [[lab2collapse[x] for x in true] for true in trues3]\n",
    "    preds4 = [[lab2collapse[x] for x in pred] for pred in preds3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B91zJL8csFpg"
   },
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "i6IUw7gqVxR2",
    "outputId": "902abe15-0841-473c-822a-79f5444e74ed"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, 10000_data\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "if collapse_labels:\n",
    "    print(f1_score(trues4, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "E2Dy4vXF_Zco",
    "outputId": "b61a3b56-2bf5-41eb-cd8d-e7529ab3ce0e"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, 10000_data\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "if collapse_labels:\n",
    "    print(f1_score(trues4, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "J1opLSPOHov7",
    "outputId": "11db2a3c-bdbb-4f98-82c7-8de005d8f187"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "if collapse_labels:\n",
    "    print(f1_score(trues4, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0Nb5mGbAC-qU",
    "outputId": "61294286-be41-4a99-bdfd-c176ad5d4f74"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "print(f1_score(trues2, preds2))\n",
    "print(f1_score(trues3, preds3))\n",
    "if collapse_labels:\n",
    "    print(f1_score(trues4, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "0SImrrbtDrp_",
    "outputId": "aaeccab6-5ac6-4a31-a2da-9e84cc245e1f"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "pXVUHO33HsMt",
    "outputId": "29dc1a78-1b7d-4833-f232-4357fc3acbcf"
   },
   "outputs": [],
   "source": [
    "# max_len=40, collapsed_labels, bert+BiLSTM, full_data\n",
    "metric = FlatScore('precision', 'macro', trues=trues, preds=preds)\n",
    "metric.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_VLTyE0stk8"
   },
   "source": [
    "inspect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "p6Xh0prN-BZv",
    "outputId": "a3df06e2-d658-4123-ddd8-6e10b0dcc48d"
   },
   "outputs": [],
   "source": [
    "i = 22\n",
    "print(\"truth tags\",'\\n', trues[i], '\\n')\n",
    "print(\"predictions\", '\\n', preds[i], '\\n')\n",
    "print(\"truth labels\", '\\n', np.array(labes[i]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLvF-3Q59L4d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shLfoQKlk56G"
   },
   "source": [
    "### ELMo + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CuD-58XL9LxV"
   },
   "outputs": [],
   "source": [
    "https://colab.research.google.com/drive/1jNrJQIpwZaJoiq-Y_t9ALPc_g1QchqZB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGpkEWGSDwr3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxSKFFH27rLI"
   },
   "source": [
    "## John's Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvX6orNi34S-"
   },
   "outputs": [],
   "source": [
    "https://colab.research.google.com/drive/1AnrBf23MibMx1KbWlk8KcOYMKnyOn09v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJOxrKys34PT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3d8QAK5dJf2a"
   },
   "source": [
    "## Scrap Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_Wj2eYpJhvb"
   },
   "outputs": [],
   "source": [
    "\n",
    "agg_func = lambda s: tuple([(w, p, t) for w, p, t in zip(s[\"word\"], s['pos'], s[\"tag\"])])\n",
    "groups = xdat.groupby(\"sentence\").apply(agg_func)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in groups]\n",
    "labels = [[s[2] for s in sent] for sent in groups]\n",
    "\n",
    "\n",
    "# encode y labels\n",
    "labels_unique = sorted(set(xdat[\"tag\"].values))\n",
    "lab2idx = {t: i for i, t in enumerate(labels_unique)}\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "attention_masks = (input_ids > 0).astype(int)\n",
    "\n",
    "tags = pad_sequences([[lab2idx.get(l) for l in lab] for lab in labels],\n",
    "                    maxlen=MAX_LEN, value=lab2idx[\"O\"], padding=\"post\",\n",
    "                    dtype=\"long\", truncating=\"post\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of NLP_v2 - i2k exploration.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "42249e2c7ebe4a7991fa45cacb0e4142": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886b53c6476041d38d9cbc9a700c1c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3970781a311470c9cd6745fdc24b0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed2a8f60d59744e2a9e7397cf8f3e298",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b26c64e1f58f477890c7d14bdb4136e6",
      "value": 231508
     }
    },
    "b26c64e1f58f477890c7d14bdb4136e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e9e0e8432805434189265922ab8df53e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed2a8f60d59744e2a9e7397cf8f3e298": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f31fd09a08624689a911c81114c5e2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3970781a311470c9cd6745fdc24b0ba",
       "IPY_MODEL_ff9f3419d8d64f9d85c3d78dca5ca1ee"
      ],
      "layout": "IPY_MODEL_42249e2c7ebe4a7991fa45cacb0e4142"
     }
    },
    "ff9f3419d8d64f9d85c3d78dca5ca1ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9e0e8432805434189265922ab8df53e",
      "placeholder": "",
      "style": "IPY_MODEL_886b53c6476041d38d9cbc9a700c1c40",
      "value": " 232k/232k [00:00&lt;00:00, 998kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习入门及简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 发展简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人类一直试图让机器具有智能，也就是人工智能（Artificial Intelligence）。从上世纪50年代，人工智能的发展经历了“推理期”，通过赋予机器逻辑推理能力使机器获得智能，当时的AI程序能够证明一些著名的数学定理，但由于机器缺乏知识，远不能实现真正的智能。因此，70年代，人工智能的发展进入“知识期”，即将人类的知识总结出来教给机器，使机器获得智能。在这一时期，大量的专家系统问世，在很多领域取得大量成果，但由于人类知识量巨大，故出现“知识工程瓶颈”。 \n",
    "\n",
    "无论是“推理期”还是“知识期”，机器都是按照人类设定的规则和总结的知识运作，永远无法超越其创造者，其次人力成本太高。于是，一些学者就想到，如果机器能够自我学习问题不就迎刃而解了吗！机器学习（Machine Learning）方法应运而生，人工智能进入“机器学习时期”。“机器学习时期”也分为三个阶段，80年代，连接主义较为流行，代表工作有感知机（Perceptron）和神经网络（Neural Network）。90年代，统计学习方法开始占据主流舞台，代表性方法有支持向量机（Support Vector Machine），进入21世纪，深度神经网络被提出，连接主义卷土从来，随着数据量和计算能力的不断提升，以深度学习（Deep Learning）为基础的诸多AI应用逐渐成熟。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能 - 机器学习 - 深度学习三者的关系如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlrange1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能 - 机器学习 - 深度学习三者发展的时间顺序："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlrange2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlperiod.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 机器学习分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下图，机器学习分类，可以按照模型、任务、方法进行分类。<br>\n",
    "蓝色背景为根据理论分类<br>\n",
    "橙色背景为根据任务分类<br>\n",
    "绿色背景为根据方法分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlclass.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 根据学习理论分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 有监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当训练样本带有标签时是有监督学习, 可以预测数值型数据回归，预测分类标签分类，预测顺序排序等。<br>\n",
    "常用场景：<br>\n",
    "手写文字/ 语音/ 图像识别<br>\n",
    "情感分析<br>\n",
    "基因诊断 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>谨记：刚开始机器学习的时候，经过会先学习有监督学习，而且会使用鸢尾花、mnist做一些具体的练习，但是，但是，在实际工作中，尤其是刚开展机器学习的时候，并不会有已经分类好的样本，几乎所有全新开始的机器学习的项目，都是先从无监督学习开始做聚类相关的尝试</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/superviser.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练样本全部无标签时是无监督学习，无监督学习的主要作用，是使得样本物以类聚。便于之后的分类等有监督学习进行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体的算法有聚类，异常检测等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例：<br>\n",
    "视频分析<br>\n",
    "社交网站解析<br>\n",
    "文字相似度检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/nonsuperviser.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "强化学习是一个学习最优策略（policy），可以让本体（agent）在特定环境（environment）中，根据当前状态（state），做出行动（action），从而获得最大回报（reward）。强化学习和有监督学习最大的不同是，每次的决定没有对与错，而是希望获得最多的累计奖励。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "著名的Alpha Go，就是强化学习的典型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例：<br>\n",
    "机器人自动控制 <br>\n",
    "计算机游戏中的人工智能<br>\n",
    "人机对话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/reinforce.gif' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 根据任务类型分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据任务类型分类可以分为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归模型又叫预测模型，输出是一个不能枚举的数值，比如房价预测，股价预测等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类模型又分为二分类模型和多分类模型，常见的二分类问题有垃圾邮件过滤，常见的多分类问题有文档自动归类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 结构化学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结构化学习模型的输出不再是一个固定长度的值，如图片语义分析，输出是图片的文字描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 根据方法角度分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性模型较为简单，但作用不可忽视，线性模型是非线性模型的基础，很多非线性模型都是在线性模型的基础上变换而来的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 非线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非线性模型又可以分为传统机器学习模型，如SVM，KNN，决策树等，和深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 机器学习与其他学科的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlandother.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 机器学习算法的思维导航图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlamind.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 机器学习应用准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学对于机器学习来说，概率论与数理统计是方法论，线性代数是数据载体，而高等数学则是工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举个例子，聚类所需要的求距离或相似度的公式集合："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/distance.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "附一篇我在简书所写的： [如何有效自学或复习高等数学](https://www.jianshu.com/p/5f0a7fb31e72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "附上一个秘诀：可以找B站找数学学习视频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/math.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 高等数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要掌握的包括微积分，傅里叶级数，泰勒级数等。至少能够理解如何通过对数运算，导数运算降低算法复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性代数中涉及的向量、矩阵运算，是机器学习数据处理的基础，需要掌握的包括：行列式，矩阵，向量，线性方程组，矩阵特征值，特征向量，二次型等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 概率论与数理统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要掌握的包括随机事件与概率；离散型随机变量；连续型随机变量等等。Mark: 贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/bayes.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 程序语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习的初学者，普遍需要面对一个问题：\n",
    "\n",
    "到底学习哪个编程语言？\n",
    "\n",
    "答案可能会让你惊讶：对高手来说，这关系不大。只要你了解所选语言的机器学习库和工具，语言本身其实没那么重要。\n",
    "\n",
    "但是近一两年，Python异军突起，已经支持大部分主流机器学习算法组件库，甚至各大知名公司，如Google, Facebook, OpenAI等，发布的新的组件库，都以python为优先发布语言。\n",
    "\n",
    "相当多的机器学习库支持多种编程语言。当然，取决于你在公司中的开发角色和你需要实现的任务，有些语言、库和工具会比其他的更高效。下面，我们来看看几大主流机器学习语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 R语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/r.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R 是一个专门设计来进行数据计算的语言工具。在大规模数据挖掘、可视化和报告的应用场景中，它处于领先地位。通过 CRAN 资源库，你能轻易获得海量工具包，能应用于几乎所有的机器学习算法、数据测试和分析过程。\n",
    "\n",
    "R 语言用于表达关系、转化数据以及进行并行操作的语法十分优雅，但略显深奥。\n",
    "\n",
    "近年来，Python逐渐抢走更多用户。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/matlab.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATLAB 在学术界十分普及，这是因为：\n",
    "\n",
    ">它强大的数学处理能力；<br>\n",
    "对代数、微积分有丰富支持；<br>\n",
    "支持符号计算；<br>\n",
    "对不同学科（从数字信号处理到计算生物学）有一系列丰富的工具箱。<br>\n",
    "\n",
    "这门基于矩阵的语言，经常应用于机器学习算法的原型设计，有时还被用于开发复杂的解决方案。\n",
    "\n",
    "它的商用许可特别贵，但对有些企业用户来说也许值得，因为它可以大幅减少开发、研究耗费的时间和精力。\n",
    "\n",
    "AI 大牛吴恩达就推荐初学者使用 Octave 或 MATLAB 入门。\n",
    "\n",
    "相比之下，Octave 是 MATLAB 的一个免费替代品，它们十分相似，有几乎相同的语法。\n",
    "\n",
    "只是 Octave 的工具箱更少一些，IDE 也不如 MATLAB 成熟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/python.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然 Python 是一门通用型的编程、编写脚本的语言，但它逐渐在数据科学家和机器学习工程师之间流行起来。\n",
    "\n",
    "与 R 和 MATLAB 不同的是，数据处理和科学计算的惯用语法并没有内置于Python语言中，但 NumPy、SciPy 和 Pandas 这些库把 Python 这方面的的功能性提到了与 R 和 MATLAB 同等的水平。还有人认为这使 Python 的语法更易用。\n",
    "\n",
    "有海量开源框架支持 Python：比如 Scikit-learn、Theano、TensorFlow、Keras、Spacy、Gensim、Pytorch、NLTK、etc.\n",
    "\n",
    "这些专业机器学习库使开发者训练机器学习模型更便捷，有的还能很好地支持分布式计算。\n",
    "\n",
    "通常，这些资料库中关乎性能表现的代码，大多数仍然用 C 或 C++ 编写，有的甚至用 Fortran；Python 的角色主要是作为 wrappers 或者 API。R语言包与之类似。\n",
    "\n",
    "Python生态系统最大的优势在于：用它组合出一个复杂的端到端产品或服务比较容易，比如说使用 Django 或 Flask 的网络应用，还有使用 PyQt 的桌面应用，甚至是使用 ROS 的自主机器人代理。\n",
    "\n",
    "值得一提的是，慕课三巨头 （edX, Coursera, and Udacity）全都提供了Python 的入门课程。另外，包括 MIT、加州大学伯克利分校在内的美国顶级学府，已经把 Python 作为计算机新生的必修语言。可以预期，将来会有更多的 IT 顶级名校转向 Python，与之相对的它在工业界的不断普及。\n",
    "\n",
    "总而言之，在机器学习领域，Python 是一个全能多面手"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>本课程都是基于Python相关的机器学习组件包</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 Java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/java.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Java 是大多数软件工程师的选择。这是由于在面向对象的编程中，它干净、一致的执行方式；以及使用 JVMs 的平台独立性。它牺牲了简洁和灵活性，以使代码更清楚明白，并提高可靠性。这使它广泛应用于重要级别较高的企业软件系统中。为了维持相同水平的可靠性，并避免编写出乱七八糟的界面，正在使用 Java 的企业倾向于在机器学习应用中继续使用该语言。\n",
    "\n",
    "在分析和设计原型上，java 有许多很有用的工具和库（比如 Weka）。\n",
    "\n",
    "除此之外，在开发大规模分布式学习系统上，Java 有很多一流的选择：比如 Spark+MLlib, Mahout, H2O 和 Deeplearning4j。\n",
    "\n",
    "腾讯一个月前开源的大数据计算平台 Angel 也是使用的 Java。\n",
    "\n",
    "这些框架/库对业界标准的数据处理和存储系统十分友好（比如Hadoop/HDFS），使它们之间的兼容、整合十分方便。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5 C / C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/c.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C/C++ 是编写底层软件的理想语言，比如操作系统的某部分或网络草案。\n",
    "\n",
    "计算速度和内存效率在这些应用场景中十分关键。出于同样的原因，它们也是执行机器学习底层步骤的通用选项。\n",
    "\n",
    "但是，由于缺乏对数据处理的惯用抽象化，而且内存管理加重了写代码的负担，使它们对初学者十分不友好。开发完整的端到端系统中使用 C/C++ 也是一项负担。\n",
    "\n",
    "在嵌入式系统的例子中，比如智能设备、汽车和传感器，使用 C 或者 C++ 语言可能是必需的。\n",
    "\n",
    "若现有平台基础或特定应用已使用了 C/C++，使用它们会更方便。\n",
    "\n",
    "另外，基于 C/C++ 的机器学习库也有不少，比如 LibSVM, Shark 和 mlpack。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 学习书籍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习相关书籍有很多，如果直接扑到理论性特别强的书籍，可能放弃的概率非常大，可以先看看简单的基于python的实践书籍："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 简单实践与学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《机器学习实战经典》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook1.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《实用机器学习》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook2.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 深入理论学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "周志华老师的西瓜书《机器学习》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook4.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "李航老师的《统计学习方法》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 当红的深度学习书籍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook6.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4 自然语言处理相关书籍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlbook7.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 学习视频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看书太累，感觉精力憔悴的话，也可以尝试看一些著名科学家们的课程视频。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些视频从哪里找呢？强烈推荐：<b>B站！！！</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "印象中B站，貌似是各种动漫相关视频集散地，有宅一族的的天堂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/b.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是因为其坚决不做广告的神特性，而且乐意上传机器学习相关的视频的up主特别多，所以大家如果找到自己想学的课程，就可以钉在这里不走了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐的视频有: 台湾林轩田老师的：[机器学习基石](https://www.bilibili.com/video/av4294020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "吴恩达老师的：[机器学习-吴恩达](https://www.bilibili.com/video/av9912938)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "李宏毅老师的：[李宏毅机器学习2017](https://www.bilibili.com/video/av10590361)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "邹博老师的：[机器学习升级版VII](https://www.bilibili.com/video/av22660033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "莫烦的神经网络系列课程：[Tensorflow搭建自己的神经网络](https://www.bilibili.com/video/av16001891)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我收藏的视频截图如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mlvideo.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 GITHUB课件获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GITHUB是全球最大的同性交友站点基地，几乎每位程序员都会有一个github的账号，然后有事没事就git clone一个别人的project玩玩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/github.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为如此活跃的技术开源站点，开源的机器学习相关的代码学习库，就相当多了，比如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorflow](https://github.com/tensorflow/tensorflow) \n",
    "\n",
    "[KERAS](https://github.com/keras-team/keras)\n",
    "\n",
    "[deep-learning-with-keras-notebooks](https://github.com/erhwenkuo/deep-learning-with-keras-notebooks)\n",
    "\n",
    "[data-science-complete-tutorial](https://github.com/zekelabs/data-science-complete-tutorial)\n",
    "\n",
    "[Gensim](https://github.com/RaRe-Technologies/gensim)\n",
    "\n",
    "[NLP with Python](https://github.com/susanli2016/NLP-with-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 机器学习常用的组件库 (基于python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy是在python中用于科学计算和数据操作的最基本和强大的包。\n",
    "\n",
    "如果你打算从事数据分析或机器学习项目，那么几乎必须了解numpy的使用方式。\n",
    "\n",
    "Numpy的许多函数不仅是用C实现了，还使用了BLAS（一般Windows下link到MKL的，Linux下link到OpenBLAS）。基本上那些BLAS实现在每种操作上都进行了高度优化，例如使用AVX向量指令集，甚至能比你自己用C实现快上许多，更不要说和用Python实现的比。\n",
    "\n",
    "因为其他用于数据分析的包（比如Pandas）是建立在numpy之上的，而用于构建机器学习应用程序的scikit-learn包也同样适用于numpy。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/numpy.jpeg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 是基于 NumPy 的一个开源 Python 库，它被广泛用于快速分析数据，以及数据清洗和准备等工作。它的名字来源是由“ Panel data”（面板数据，一个计量经济学名词）两个单词拼成的。简单地说，你可以把 Pandas 看作是 Python 版的 Excel。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过Pandas构建，清洗，统计机器学习相关的数据，将非常人性化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/pandas.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciKit learn的简称是SKlearn，是一个python库，专门用于机器学习的模块。 \n",
    "\n",
    "<b>SciKit learn因使用的都是非深度学习神经网络的算法与模型，所以又被称之为old school机器学习算法组件包</b>\n",
    "\n",
    "以下是它的官方网站，文档等资源都可以在里面找到http://scikit-learn.org/stable\n",
    "\n",
    "SKlearn包含的机器学习方式： \n",
    "\n",
    "分类，回归，无监督，数据降维，数据预处理等等，包含了常见的大部分机器学习方法。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/scikit-learn.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn的算法推荐图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/scikit-learn_a.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn强大的数据库：http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实际举例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 鸢尾花数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:23:34.827859Z",
     "start_time": "2023-02-08T06:23:31.065594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#调用模块\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "#导入数据和标签\n",
    "data_X = data.data\n",
    "data_y = data.target\n",
    "print(data_X[:10])\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 波士顿房价数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:23:37.969455Z",
     "start_time": "2023-02-08T06:23:37.934493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.006  18.      2.31    0.      0.538   6.575  65.2     4.09    1.\n",
      "  296.     15.3   396.9     4.98 ]\n",
      " [  0.027   0.      7.07    0.      0.469   6.421  78.9     4.967   2.\n",
      "  242.     17.8   396.9     9.14 ]\n",
      " [  0.027   0.      7.07    0.      0.469   7.185  61.1     4.967   2.\n",
      "  242.     17.8   392.83    4.03 ]\n",
      " [  0.032   0.      2.18    0.      0.458   6.998  45.8     6.062   3.\n",
      "  222.     18.7   394.63    2.94 ]\n",
      " [  0.069   0.      2.18    0.      0.458   7.147  54.2     6.062   3.\n",
      "  222.     18.7   396.9     5.33 ]\n",
      " [  0.03    0.      2.18    0.      0.458   6.43   58.7     6.062   3.\n",
      "  222.     18.7   394.12    5.21 ]\n",
      " [  0.088  12.5     7.87    0.      0.524   6.012  66.6     5.561   5.\n",
      "  311.     15.2   395.6    12.43 ]\n",
      " [  0.145  12.5     7.87    0.      0.524   6.172  96.1     5.95    5.\n",
      "  311.     15.2   396.9    19.15 ]\n",
      " [  0.211  12.5     7.87    0.      0.524   5.631 100.      6.082   5.\n",
      "  311.     15.2   386.63   29.93 ]\n",
      " [  0.17   12.5     7.87    0.      0.524   6.004  85.9     6.592   5.\n",
      "  311.     15.2   386.71   17.1  ]]\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#换种方式调用模块，注意区别\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "loaded_data = datasets.load_boston()\n",
    "#导入数据\n",
    "data_X = loaded_data.data\n",
    "data_y = loaded_data.target\n",
    "print(data_X[:10])\n",
    "print(data_y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方对每种数据都给出了使用示例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/scikit-learn_boston.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn的各个算法的学习模式都很类似，学会一个，其他的算法使用模式都差不多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 鸢尾花使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:23:54.011473Z",
     "start_time": "2023-02-08T06:23:53.541087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测分类结果\n",
      "[0 0 0 2 0 1 0 1 1 2 1 1 1 1 0 1 0 1 0 0 1 2 1 1 2 2 0 1 1 1 1 0 1 1 2 2 2\n",
      " 0 1 1 2 0 0 0 0]\n",
      "实际分类结果\n",
      "[0 0 0 2 0 1 0 1 1 2 1 1 1 1 0 1 0 1 0 0 1 1 1 1 2 2 0 1 1 1 1 0 1 1 2 2 2\n",
      " 0 1 1 2 0 0 0 0]\n",
      "MSE(均方差) is 0.022222222222222223\n",
      "R2 决定系数（拟合优度）: 0.9777777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#导入模块\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "#k近邻函数\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "iris = datasets.load_iris()\n",
    "#导入数据和标签\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "#划分为训练集和测试集数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.3)\n",
    "#设置knn分类器\n",
    "knn = KNeighborsClassifier()\n",
    "#进行训练\n",
    "knn.fit(X_train,y_train)\n",
    "#使用训练好的knn进行数据预测\n",
    "y_hat = knn.predict(X_test)\n",
    "print('预测分类结果')\n",
    "print(y_hat)\n",
    "print('实际分类结果')\n",
    "print(y_test)\n",
    "mse = np.average((y_hat - np.array(y_test)) ** 2)  # Mean Squared Error\n",
    "print('MSE(均方差) is {0}'.format(mse))\n",
    "print('R2 决定系数（拟合优度）: {0}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 波士顿房价数据使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:24:05.290982Z",
     "start_time": "2023-02-08T06:24:05.272670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.004 25.026 30.568 28.607 27.944 25.256 23.002 19.536 11.524 18.92 ]\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9]\n",
      "MSE(均方差) is 21.894831181729206\n",
      "R2 决定系数（拟合优度）: 0.7406426641094094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#同样首先，我们调用模块\n",
    "#matplotlib是python专门用于画图的库\n",
    "from sklearn import datasets\n",
    "#调用线性回归函数\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#导入数据集\n",
    "#这里将全部数据用于训练，并没有对数据进行划分，上例中\n",
    "#将数据划分为训练和测试数据，后面会讲到交叉验证\n",
    "loaded_data = datasets.load_boston()\n",
    "data_X = loaded_data.data\n",
    "data_y = loaded_data.target\n",
    "\n",
    "#设置线性回归模块\n",
    "model = LinearRegression()\n",
    "#训练数据，得出参数\n",
    "model.fit(data_X, data_y)\n",
    "y_hat = model.predict(data_X)\n",
    "#利用模型，对新数据，进行预测，与原标签进行比较\n",
    "print(y_hat[:10])\n",
    "print(data_y[:10])\n",
    "mse = np.average((y_hat - np.array(data_y)) ** 2)  # Mean Squared Error\n",
    "print('MSE(均方差) is {0}'.format(mse))\n",
    "print('R2 决定系数（拟合优度）: {0}'.format(model.score(data_X, data_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 梯度提升算法包 (GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度提升算法其实是一个算法框架，即可以将已有的分类或回归算法放入其中，得到一个性能很强大的算法。\n",
    "\n",
    "梯度提升算法总共需要进行M次迭代，每次迭代产生一个模型，我们需要让每次迭代生成的模型对训练集的损失函数最小，而如何让损失函数越来越小呢？我们采用梯度下降的方法，在每次迭代时通过向损失函数的负梯度方向移动来使得损失函数越来越小，这样我们就可以得到越来越精确的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT是以决策树（CART）为基学习器的GB算法，xgboost扩展和改进了GDBT，xgboost算法更快，准确率也相对高一些。\n",
    "\n",
    "在很多机器学习大赛中，面对分类算法应用，即使不使用当红炸子鸡：神经网络深度学习算法，仅仅通过XGBOOST甚至随机森林，效果也不会太差~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost就是一个监督模型，那么我们的第一个问题就是：xgboost对应的模型是什么？\n",
    "答案就是一堆CART树。\n",
    "此时，可能我们又有疑问了，CART树是什么？这个问题请查阅其他资料。\n",
    "\n",
    "然后，一堆树如何做预测呢？答案非常简单，就是将每棵树的预测值加到一起作为最终的预测值，可谓简单粗暴。\n",
    "\n",
    "即将一堆弱分类器叠加，构成强分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图：多个决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/multitree.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在寻找最佳分割点时，考虑传统的枚举每个特征的所有可能分割点的贪心法效率太低，xgboost实现了一种近似的算法。大致的思想是根据百分位法列举几个可能成为分割点的候选者，然后从候选者中根据上面求分割点的公式计算找出最佳的分割点。\n",
    "\n",
    "xgboost考虑了训练数据为稀疏值的情况，可以为缺失值或者指定的值指定分支的默认方向，这能大大提升算法的效率，paper提到50倍。\n",
    "\n",
    "特征列排序后以块的形式存储在内存中，在迭代中可以重复使用；虽然boosting算法迭代必须串行，但是在处理每个特征列时可以做到并行。\n",
    "\n",
    "按照特征列方式存储能优化寻找最佳的分割点，但是当以行计算梯度数据时会导致内存的不连续访问，严重时会导致cache miss，降低算法效率。paper中提到，可先将数据收集到线程内部的buffer，然后再计算，提高算法的效率。\n",
    "\n",
    "xgboost 还考虑了当数据量比较大，内存不够时怎么有效的使用磁盘，主要是结合多线程、数据压缩、分片的方法，尽可能的提高算法的效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:24:18.291967Z",
     "start_time": "2023-02-08T06:24:15.667728Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:24:22.035978Z",
     "start_time": "2023-02-08T06:24:20.851926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[0]\teval-mlogloss:0.74118\ttrain-mlogloss:0.74166\n",
      "[1]\teval-mlogloss:0.53239\ttrain-mlogloss:0.53237\n",
      "[2]\teval-mlogloss:0.39846\ttrain-mlogloss:0.39609\n",
      "[3]\teval-mlogloss:0.30859\ttrain-mlogloss:0.30288\n",
      "[4]\teval-mlogloss:0.24713\ttrain-mlogloss:0.23719\n",
      "[5]\teval-mlogloss:0.20448\ttrain-mlogloss:0.18996\n",
      "y_hat\n",
      "[0. 1. 1. 0. 2. 1. 2. 0. 0. 2. 1. 0. 2. 1. 1. 0. 1. 1. 0. 0. 1. 1. 2. 0.\n",
      " 2. 1. 0. 0. 1. 2. 1. 2. 1. 2. 2. 0. 1. 0. 1. 2. 2. 0. 2. 2. 1. 2. 0. 0.\n",
      " 0. 1.]\n",
      "测试集正确率:\t 0.98\n",
      "训练集正确率:\t 0.98\n",
      "END.....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "#导入数据和标签\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=50)\n",
    "\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 4, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "bst = xgb.train(param, data_train, num_boost_round=6, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "print('y_hat')\n",
    "print(y_hat)\n",
    "result = y_test == y_hat\n",
    "print('测试集正确率:\\t', float(np.sum(result)) / len(y_hat))\n",
    "\n",
    "y_hat = bst.predict(data_train)\n",
    "result = y_train == y_hat\n",
    "print('训练集正确率:\\t', float(np.sum(result)) / len(y_hat))\n",
    "print('END.....\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与Logisitic回归以及随机森林的效果对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T06:24:41.112432Z",
     "start_time": "2023-02-08T06:24:40.905975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 训练集正确率： 0.97\n",
      "LogisticRegression 测试集正确率： 0.96\n",
      "RandomForest 训练集正确率： 1.0\n",
      "RandomForest 测试集正确率： 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models = [('LogisticRegression', LogisticRegressionCV(Cs=10, cv=3)),\n",
    "          ('RandomForest', RandomForestClassifier(n_estimators=30, criterion='gini'))]\n",
    "for name, model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(name, '训练集正确率：', accuracy_score(y_train, model.predict(x_train)))\n",
    "    print(name, '测试集正确率：', accuracy_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 神经网络深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络：一种可以通过观测数据使计算机学习的仿生语言范例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习：一组强大的神经网络学习技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络和深度学习目前提供了针对图像识别，语音识别和自然语言处理领域诸多问题的最佳解决方案。\n",
    "\n",
    "传统的编程方法中，我们告诉计算机如何去做，将大问题划分为许多小问题，精确地定义了计算机很容易执行的任务。\n",
    "\n",
    "而神经网络不需要我们告诉计算机如何处理问题，而是通过从观测数据中学习，计算出他自己的解决方案。\n",
    "\n",
    "自动地从数据中学习看起来很有前途。然而直到2006年我们都不知道如何训练神经网络使得它比传统的方法更好，除了一些特定问题。直到2006年称为深度神经网络的学习技术被提出，这些技术现在被称为深度学习。\n",
    "\n",
    "今天，深度神经网络和深度学习在计算机视觉、语音识别和自然语言处理等许多重要问题上取得了出色的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/deepnet.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深度学习常用算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 卷积神经网络（CNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，卷积神经网络是一种深度前馈人工神经网络，已成功地应用于图像识别。\n",
    "\n",
    "卷积神经网络，是一种前馈神经网络，人工神经元可以响应周围单元，可以进行大型图像处理。卷积神经网络包括卷积层和池化层。\n",
    "\n",
    "卷积神经网络包括一维卷积神经网络、二维卷积神经网络以及三维卷积神经网络。一维卷积神经网络常应用于序列类的数据处理；二维卷积神经网络常应用于图像类文本的识别；三维卷积神经网络主要应用于医学图像以及视频类数据识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnn.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用卷积神经网络实现图像分类、物体识别、图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer - Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/transformer.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bert - 基于Transformer统一NLP应用的基础模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/bert.jpeg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/bert2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ViT - Vision Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为Transformer的通用性，目前深度学习，无论是NLP领域还是CV领域，基于Transformer的论文与实践，有一统天下之嫌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/vit1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT的基本思路，是将一张图片，切割成N个16x16的patches，每一个patch即构成了类似自然语言处理的Token（对应word级别），于是就可以直接套用自然语言处理的Transformer框架，来做计算机视觉任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/vit2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer之前流行的循环神经网络（RNN）（Transformer之后，NLP领域已经由Bert一统天下）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环神经网络（RNN：Recurrent neural networks）是具有时间联结的前馈神经网络：它们有了状态，通道与通道之间有了时间上的联系。神经元的输入信息，不仅包括前一神经细胞层的输出，还包括它自身在先前通道的状态。\n",
    "\n",
    "这就意味着：你的输入顺序将会影响神经网络的训练结果：相比先输入“曲奇饼”再输入“牛奶”，先输入“牛奶”再输入“曲奇饼”后，或许会产生不同的结果。RNN存在一大问题：梯度消失（或梯度爆炸，这取决于所用的激活函数），信息会随时间迅速消失，正如FFNN会随着深度的增加而失去信息一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 长短期记忆（LSTM）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "长短期记忆（LSTM：Long / short term memory）网络试图通过引入门结构与明确定义的记忆单元来解决梯度消失/爆炸的问题。\n",
    "\n",
    "这更多的是受电路图设计的启发，而非生物学上某种和记忆相关机制。每个神经元都有一个记忆单元和三个门：输入门、输出门、遗忘门。这三个门的功能就是通过禁止或允许信息流动来保护信息。\n",
    "\n",
    "输入门决定了有多少前一神经细胞层的信息可留在当前记忆单元，输出层在另一端决定下一神经细胞层能从当前神经元获取多少信息。遗忘门乍看很奇怪，但有时候遗忘部分信息是很有用的：比如说它在学习一本书，并开始学一个新的章节，那遗忘前面章节的部分角色就很有必要了。\n",
    "\n",
    "实践证明，LSTM可用来学习复杂的序列，比如像莎士比亚一样写作，或创作全新的音乐。值得注意的是，每一个门都对前一神经元的记忆单元赋有一个权重，因此会需要更多的计算资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lstm.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 门循环单元（GRU）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "门循环单元（GRU : Gated recurrent units）是LSTM的一种轻量级变体。它们少了一个门，同时连接方式也稍有不同：它们采用了一个更新门（update gate），而非LSTM所用的输入门、输出门、遗忘门。\n",
    "\n",
    "更新门决定了保留多少上一个状态的信息，还决定了收取多少来自前一神经细胞层的信息。重置门（reset gate）跟LSTM遗忘门的功能很相似，但它存在的位置却稍有不同。它们总是输出完整的状态，没有输出门。多数情况下，它们跟LSTM类似，但最大的不同是：GRU速度更快、运行更容易（但函数表达力稍弱）。\n",
    "\n",
    "在实践中，这里的优势和劣势会相互抵消：当你你需要更大的网络来获取函数表达力时，这样反过来，性能优势就被抵消了。在不需要额外的函数表达力时，GRU的综合性能要好于LSTM。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gru.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BiRNN、BiLSTM、BiGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双向循环神经网络（BiRNN：Bidirectional recurrent neural networks）、双向长短期记忆网络（BiLSTM：bidirectional long / short term memory networks ）和双向门控循环单元（BiGRU：bidirectional gated recurrent units）在图表中并未呈现出来，因为它们看起来与其对应的单向神经网络结构一样。\n",
    "\n",
    "所不同的是，这些网络不仅与过去的状态有连接，而且与未来的状态也有连接。比如，通过一个一个地输入字母，训练单向的LSTM预测“鱼（fish）”（在时间轴上的循环连接记住了过去的状态值）。在BiLSTM的反馈通路输入序列中的下一个字母，这使得它可以了解未来的信息是什么。这种形式的训练使得该网络可以填充信息之间的空白，而不是预测信息。因此，它在处理图像时不是扩展图像的边界，而是填补一张图片中的缺失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双向LSTM图例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/bilstm.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成对抗网络（Generative Adversarial Nets）是Ian Goodfellow 等人2014年的论文《Generative Adversarial Nets》中提出，它是非监督学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。\n",
    "\n",
    "生成对抗网络是由一个生成网络（Generator）与一个判别网络（Discriminator）组成。生成网络从潜在空间（latent space）中随机采样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入则是生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gan.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深度学习常用组件包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.171px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

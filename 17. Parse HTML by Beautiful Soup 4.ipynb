{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫基础: Requests + BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“爬虫”，是访问互联网网页 ->定位网页元素 -> 爬取网页内容的过程。<br>\n",
    "在实际工作中，访问的工作交给urllib或者requests完成；爬取的工作则交给xpath, BeatifulSoup乃至正则合作完成。<br>\n",
    "想学习爬虫知识，首先需要了解HTTP基础请求方法：get和post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP方法：GET和POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>请注意，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的</font><br>\n",
    "如：```https://www.baidu.com/s?ie=utf-8&wd=python```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有关 GET 请求的其他一些注释：\n",
    "\n",
    "* GET 请求可被缓存\n",
    "* GET 请求保留在浏览器历史记录中\n",
    "* GET 请求可被收藏为书签\n",
    "* GET 请求不应在处理敏感数据时使用\n",
    "* GET 请求有长度限制\n",
    "* GET 请求只应当用于取回数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>请注意，查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的</font><br>\n",
    "```\n",
    "POST http://dcms-ml-dev.dc68032.easn.morningstar.com/automation/api/namesimilar HTTP/1.1\n",
    "Host: dcms-ml-dev.dc68032.easn.morningstar.com\n",
    "Connection: keep-alive\n",
    "Content-Length: 103\n",
    "accept: application/json\n",
    "Origin: http://dcms-ml-dev.dc68032.easn.morningstar.com\n",
    "User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\n",
    "Content-Type: application/json\n",
    "Referer: http://dcms-ml-dev.dc68032.easn.morningstar.com/apidocs/\n",
    "Accept-Encoding: gzip, deflate\n",
    "Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\n",
    "{\n",
    "  \"country\": \"\",\n",
    "  \"onlyactive\": \"0\",\n",
    "  \"querytype\": \"share\",\n",
    "  \"text\": \"S&P 500\",\n",
    "  \"universe\": \"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有关 POST 请求的其他一些注释：\n",
    "\n",
    "* POST 请求不会被缓存\n",
    "* POST 请求不会保留在浏览器历史记录中\n",
    "* POST 不能被收藏为书签\n",
    "* POST 请求对数据长度没有要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/2018-09-17 12_15_17-HTTP 方法GET对比POST.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requests是一个很实用的Python HTTP客户端库，编写爬虫和测试服务器响应数据时经常会用到。可以说，Requests 完全满足如今网络的需求。<br>\n",
    "Requests的官方文档 http://docs.python-requests.org/en/master/ <br>\n",
    "安装方式一般采用```pip install requests``` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:20:29.588434Z",
     "start_time": "2022-11-09T09:20:29.479155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.baidu.com')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 带参数的Get请求\n",
    "这里需要加入headers，给一个user-agent伪装一下自己"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:23:36.409256Z",
     "start_time": "2022-11-09T09:23:35.128671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <Response [200]>, Whole URL: https://wappass.baidu.com/static/captcha/tuxing.html?&logid=8439454954546331348&ak=c27bbc89afca0463650ac9bde68ebe06&backurl=https%3A%2F%2Fwww.baidu.com%2Fs%3Fie%3Dutf-8%26wd%3D%25E7%259C%258B%25E7%2597%2585&signature=fd894b4f7a8c292ea071a31dce77ba10&timestamp=1667985815\n"
     ]
    }
   ],
   "source": [
    "parameters = {'ie': 'utf-8', 'wd':'看病'}\n",
    "headers = {\n",
    "\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\"}\n",
    "requestforbing = requests.get('https://www.baidu.com/s', \n",
    "                              params=parameters, \n",
    "                              headers=headers)\n",
    "# requestforbing = requests.get('https://www.baidu.com/s', params=parameters)\n",
    "# print('Response: {0}, Whole URL: {1}, Text: {2}'.format(requestforbing, requestforbing.url, requestforbing.content))\n",
    "print('Response: {0}, Whole URL: {1}'.format(requestforbing, requestforbing.url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将请求的网页内容保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:29:06.432022Z",
     "start_time": "2022-11-09T09:29:05.069269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "rstream = requests.get('https://www.baidu.com/s', \n",
    "                       params=parameters, \n",
    "                       headers=headers, \n",
    "                       stream=True)\n",
    "print(rstream)\n",
    "try:\n",
    "    with open('./html/baiduresult.html', 'wb') as fd:\n",
    "        for chunk in rstream.iter_content(1000):\n",
    "            fd.write(chunk)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[baiduresult.html](./html/baiduresult.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分的业务应用，其实都是POST请求。<br>\n",
    "现在POST请求的参数一般通过JSON字符串组成，返回的结果往往也是JSON字符串<br>\n",
    "以下是具体的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Form的形式发送请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:31:05.207323Z",
     "start_time": "2022-11-09T09:31:04.729012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.28.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-636b7359-0ab9828248ff59b80137b442\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"223.119.59.158\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "url = 'http://httpbin.org/post'\n",
    "d = {'key1': 'value1', 'key2': 'value2'}\n",
    "r = requests.post(url, data=d)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Json的形式发送请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:32:16.482413Z",
     "start_time": "2022-11-09T09:32:15.993489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Content-Length\": \"36\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.28.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-636b73a0-3456ea426cdb5f27771dd812\"\n",
      "  }, \n",
      "  \"json\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"origin\": \"223.119.59.158\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://httpbin.org/post'\n",
    "s = json.dumps({'key1': 'value1', 'key2': 'value2'})\n",
    "r = requests.post(url, data=s)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说，Beautiful Soup是python的一个库，最主要的功能是从网页抓取数据。官方解释如下：<br>\n",
    "```\n",
    "Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。\n",
    "\n",
    "Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。\n",
    "\n",
    "Beautiful Soup已成为和lxml、html5lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install beautifulsoup4\n",
    "pip install lxml\n",
    "pip install html5lib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。<br>\n",
    "<font color='red'>lxml处理具有多个pre标签的html的时候，只能解析第一个pre标签，此时建议还是通过BeautifulSoup(markup, \"html.parser\")进行解析网页</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/2018-09-17 20_05_34-Python爬虫利器二之Beautiful Soup的用法.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特别详细的内容，可以参考官方文档，下面就开始正式举例说明了~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[官方文档](https://beautifulsoup.readthedocs.io/zh_CN/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前应星宇所托，写了个爬取山东地区汽油柴油价格行情的爬虫示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/2018-09-17 20_11_54.png' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击第一个链接，可以进入明细页面:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/2018-09-17 20_14_16.png' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何实现呢？我们一步一步来~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:43:56.856927Z",
     "start_time": "2022-11-09T09:43:56.835896Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入所需要的python包\n",
    "import re\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "from bs4 import  BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置url，header，搜索文本变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:44:46.879005Z",
     "start_time": "2022-11-09T09:44:46.852645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.baidu.com/s?ie=utf-8&wd=2018年9月21日 山东地区汽油柴油价格行情 东方财富&tn=monline_4_dg'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.baidu.com/s?ie=utf-8&wd={0}&tn=monline_4_dg\"\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/600.5.17 (KHTML, like Gecko) Version/8.0.5 Safari/600.5.17\"\n",
    "}\n",
    "searchtext = \"2018年9月21日 山东地区汽油柴油价格行情 东方财富\"\n",
    "url = url.format(searchtext)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过requests完成查询，并且通过pyquery获取特定属性下面的链接信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:45:19.481781Z",
     "start_time": "2022-11-09T09:45:18.502151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('http://www.baidu.com/link?url=WxFURr8NdNMQk1A2iqnZ_BJEiKDh_rCLrKxjXI2RPLVcBL-oiMkyhEELZfKakmFuVT3JApbLmQ_x8SN9kYAaWRpSOjdcmEWra0L3v1UEX_G', b'9\\xe6\\x9c\\x8821\\xe6\\x97\\xa5\\xe4\\xb8\\xad\\xe5\\x9b\\xbd\\xe6\\xb1\\xbd\\xe3\\x80\\x81\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe5\\xb9\\xb3\\xe5\\x9d\\x87\\xe6\\x89\\xb9\\xe5\\x8f\\x91\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe5\\x88\\x86\\xe5\\x88\\xab\\xe4\\xb8\\xba9265\\xe3\\x80\\x818990\\xe5\\x85\\x83/\\xe5\\x90\\xa8 _...'), ('http://www.baidu.com/link?url=xynQzUTnNfJsHWDBed8V3nIOCNY_koQq_pXRVBZczABosacNeTmT2UtXCttSFvKqZtnoux6O9wIlj9sBSxE-IWh-nyDJ5X715RrGcFQeY9G', b'...\\xe5\\xb1\\xb1\\xe4\\xb8\\x9c\\xe5\\x9c\\xb0\\xe7\\x82\\xbc\\xe6\\xb1\\xbd\\xe6\\xb2\\xb9\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe5\\x87\\xba\\xe5\\x8e\\x82\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc, \\xe5\\x8e\\x9f\\xe6\\xb2\\xb9\\xe6\\x9c\\x80\\xe6\\x96\\xb0\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe8\\xb5\\xb0\\xe5\\x8a\\xbf_\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe5\\x8f\\xb7_...'), ('http://www.baidu.com/link?url=q_LaJnKRWQeBrYR5WorHkMjCeeHDszfFwt5mc_xyZBK3FBL2o2lmT5yXL4DTfUKWoxpQDcbxxwb_ZWMP5EZBfxyrnL2bGAM0jmBk38zuAaa', b'\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe5\\xa4\\xa7\\xe8\\xb7\\x8c\\xe8\\xa6\\x81\\xe6\\x9d\\xa5\\xe4\\xba\\x86!9\\xe6\\x9c\\x8821\\xe6\\x97\\xa5\\xe6\\x99\\x9a\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe8\\xb0\\x83\\xe6\\x95\\xb4_\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe5\\x8f\\xb7_\\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe7\\xbd\\x91'), ('http://www.baidu.com/link?url=L76abE3TMZ-GkqOBCQfbn6sWGG-wKrZmMAnm9AsqrK3c5HAq9YDUw79vq2Zg5ROH6XAMWj4MdNdOUY_QJQqSsQhxtoXZWDxvVnjekcIVx0e', b'\\xe5\\x8f\\x91\\xe6\\x94\\xb9\\xe5\\xa7\\x94:9\\xe6\\x9c\\x8821\\xe6\\x97\\xa524\\xe6\\x97\\xb6\\xe8\\xb5\\xb7\\xe5\\x9b\\xbd\\xe5\\x86\\x85\\xe6\\xb1\\xbd\\xe3\\x80\\x81\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe6\\xaf\\x8f\\xe5\\x90\\xa8\\xe5\\x88\\x86\\xe5\\x88\\xab\\xe9\\x99\\x8d\\xe4\\xbd\\x8e290\\xe5\\x85\\x83...'), ('http://www.baidu.com/link?url=z8al4JHTOAqQMA5HK55k5exiCAbJgqyQoCI3DSArlHyDfpRmLHeJT7rmzVksD6lOk_KveUII35QOrxbf3JZizhYfes3_heS59uYvmYtiGq7', b'\\xe6\\xb1\\xbd\\xe6\\xb2\\xb9\\xe3\\x80\\x81\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe4\\xb8\\x8a\\xe8\\xb0\\x83 _ \\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe7\\xbd\\x91'), ('http://www.baidu.com/link?url=nIf6gVFI4q9PQ162BZNfoPbev0Snhti0wvyq87Wy7Sx63nF5UzhHaDm_kz_wVttpRTUZkTxrH-ixac0ZrXsD0dVWeSzRStNmSFRg6dygC5_', b'...\\xe6\\x97\\xa5\\xe4\\xb8\\xad\\xe5\\x9b\\xbd\\xe6\\xb1\\xbd\\xe3\\x80\\x81\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe5\\xb9\\xb3\\xe5\\x9d\\x87\\xe6\\x89\\xb9\\xe5\\x8f\\x91\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe5\\x88\\x86\\xe5\\x88\\xab\\xe4\\xb8\\xba9290\\xe3\\x80\\x819006\\xe5\\x85\\x83/\\xe5\\x90\\xa8 _ ...'), ('http://www.baidu.com/link?url=vBpASIdUd2QVhEaL4_SAcsyu30_xM24eD9nbjeXUlO3UTESkzFCWCzxBX-Ra7b31GgVuZMHODVOxAVQQi57LmNNPYjyQ_sK_kgJbx9Pr0-u', b'\\xe6\\x97\\xa9\\xe7\\x9b\\x98\\xe5\\x86\\x85\\xe5\\x8f\\x82:\\xe5\\x9b\\xbd\\xe5\\x86\\x85\\xe6\\x88\\x90\\xe5\\x93\\x81\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe8\\xbf\\x8e\\xe5\\xb9\\xb4\\xe5\\x86\\x85\\xe7\\xac\\xac\\xe4\\xb8\\x83\\xe8\\xb7\\x8c\\xe5\\x8a\\xa0\\xe6\\xbb\\xa1\\xe4\\xb8\\x80\\xe7\\xae\\xb1\\xe6\\xb2\\xb9\\xe5\\xb0\\x91\\xe8\\x8a\\xb111.5\\xe5\\x85\\x83'), ('http://www.baidu.com/link?url=r6xjxsSGhZEU_N5gGlbRrMh76r8ZE4hZ54-z7wDXAlR-yZJMyod1BL7XLBoMMYM-1RNGPWVhURCbc-V0OX3Vza', b'\\xe5\\x85\\xa8\\xe5\\x9b\\xbd\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe6\\x95\\xb0\\xe6\\x8d\\xae _ \\xe6\\x95\\xb0\\xe6\\x8d\\xae\\xe4\\xb8\\xad\\xe5\\xbf\\x83 _ \\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe7\\xbd\\x91'), ('http://www.baidu.com/link?url=kmC3dQwlEyrXjVpwwhnwTTXw7WTJDuFJSa5psFM4ih1ahFuNwGpZSoe71izMyC1gWGnw1p1bQqL1xVq9FvGB_yA1L6bI2jycNLwdapBhc1u', b'2018\\xe5\\xb9\\xb48\\xe6\\x9c\\x8828\\xe6\\x97\\xa5\\xe5\\xb1\\xb1\\xe4\\xb8\\x9c\\xe5\\x9c\\xb0\\xe5\\x8c\\xba\\xe6\\xb1\\xbd\\xe6\\xb2\\xb9\\xe6\\x9f\\xb4\\xe6\\xb2\\xb9\\xe4\\xbb\\xb7\\xe6\\xa0\\xbc\\xe8\\xa1\\x8c\\xe6\\x83\\x85 _ \\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe7\\xbd\\x91'), ('http://www.baidu.com/link?url=qnKQwZg6R0XWQ4i_O1p8TKNBPiHjN9pXXyNOCNV_6DaV2RoN8pKz5wA0hMJ3uDa8fJVdLO2tjq1iYy7qHjJJs_', b'\\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe8\\xb4\\xa2\\xe5\\xaf\\x8c\\xe8\\xb4\\xa2\\xe7\\xbb\\x8f\\xe6\\x97\\xa9\\xe9\\xa4\\x90 11\\xe6\\x9c\\x888\\xe6\\x97\\xa5\\xe5\\x91\\xa8\\xe4\\xba\\x8c|\\xe6\\xb2\\xaa\\xe6\\xb7\\xb1|\\xe8\\xaf\\x81\\xe5\\x88\\xb8\\xe6\\x97\\xb6\\xe6\\x8a\\xa5|\\xe8\\xb4\\xa2\\xe8\\x81\\x94\\xe7\\xa4\\xbe_\\xe7\\xbd\\x91\\xe6\\x98\\x93...')]\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = 'utf-8'\n",
    "# print(response.text)\n",
    "page = pq(response.text)\n",
    "baiduurls = [(site.attr('href'), site.text().encode('utf-8')) for site in\n",
    "                page('div.result.c-container  h3.t  a').items()]\n",
    "print(baiduurls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为百度做了url转义，所以需要再用requests做一次get操作，从而获取真正需要获取的链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:47:58.951216Z",
     "start_time": "2022-11-09T09:47:57.495601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://finance.eastmoney.com/a/202209222515402613.html', '9月21日中国汽、柴油平均批发价格分别为9265、8990元/吨 _...'), ('https://caifuhao.eastmoney.com/news/20220909112204581041730', '...山东地炼汽油柴油出厂价格, 原油最新价格走势_财富号_...'), ('https://caifuhao.eastmoney.com/news/20220913111431201020600', '油价大跌要来了!9月21日晚油价调整_财富号_东方财富网'), ('https://finance.eastmoney.com/a/202209212514584054.html', '发改委:9月21日24时起国内汽、柴油价格每吨分别降低290元...'), ('https://futures.eastmoney.com/a/202211082553879687.html', '汽油、柴油价格上调 _ 东方财富网'), ('https://futures.eastmoney.com/a2/202209212514373650.html', '...日中国汽、柴油平均批发价格分别为9290、9006元/吨 _ ...'), ('http://baijiahao.baidu.com/s?id=1744617186672459773&wfr=spider&for=pc', '早盘内参:国内成品油价迎年内第七跌加满一箱油少花11.5元'), ('https://data.eastmoney.com/cjsj/yjtz/default.html', '全国油价数据 _ 数据中心 _ 东方财富网'), ('https://emwap.eastmoney.com/info/detail/20180828935429861', '2018年8月28日山东地区汽油柴油价格行情 _ 东方财富网'), ('https://dy.163.com/article/HLKP8OGF051986N4.html', '东方财富财经早餐 11月8日周二|沪深|证券时报|财联社_网易...')]\n"
     ]
    }
   ],
   "source": [
    "originalURLs = []\n",
    "for tmpurl in baiduurls:\n",
    "    tmpPage = requests.get(tmpurl[0], allow_redirects=False)\n",
    "#     print(tmpPage.text, tmpPage.headers)\n",
    "    if tmpPage.status_code == 200:\n",
    "#         print('200')\n",
    "        urlMatch = re.search(r'URL=\\'(.*?)\\'', tmpPage.text.encode('utf-8'), re.S)\n",
    "        originalURLs.append((urlMatch.group(1), tmpurl[1].decode(\"utf-8\")))\n",
    "    elif tmpPage.status_code == 302:\n",
    "#         print('302')\n",
    "        originalURLs.append((tmpPage.headers.get('location'), tmpurl[1].decode(\"utf-8\")))\n",
    "    else:\n",
    "        print('No URL found!!')\n",
    "print(originalURLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然真正的url已经都拿到了，那么我们就可以进入具体的网页一探究竟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018年9月21日', '山东地区汽油柴油价格行情', '东方财富']\n",
      "东方财富网获得信息：2018年9月21日山东地区汽油柴油价格行情 _ 东方财富网, 网址：http://finance.eastmoney.com/news/1356,20180921950557554.html\n"
     ]
    }
   ],
   "source": [
    "searcharray = searchtext.split()\n",
    "searchdate = ''\n",
    "findurl = ''\n",
    "print(searcharray)\n",
    "# print(originalURLs)\n",
    "for url in originalURLs:\n",
    "#     print(url[1], url[0])\n",
    "    if len(searcharray) >=2 \\\n",
    "            and searcharray[0] in url[1] \\\n",
    "            and searcharray[1] in url[1] \\\n",
    "            and ('futures.eastmoney' in url[0] or \n",
    "                 'finance.eastmoney' in url[0]):\n",
    "        print(\"东方财富网获得信息：{0}, 网址：{1}\".format(url[1], url[0]))\n",
    "        searchdate = searchtext.split()[0]\n",
    "        findurl = url[0]\n",
    "        break\n",
    "#             parsegasinfo(searchdate, url[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然拿到最终需要去爬取的URL了，那么就需要BeautifulSoup去拿文本了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2018年9月21日山东地区汽油柴油价格行情 _ 东方财富网\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "        var __WAPURL = \"https://wap.eastmoney.com/a/20180921950557554.html\";\r\n",
      "        var _NewsTag = '汽油,柴油,地区,';\r\n",
      "        var _NewsId = '20180921950557554';\r\n",
      "        var _us_zixun_Id = '20180921950557554';\r\n",
      "        var _YM = 'finance';\r\n",
      "        var _CMSHJ = 'prod';\r\n",
      "        var _ISComment = true;\r\n",
      "        function getQueryString(name) {\r\n",
      "            var reg = new RegExp(\"(^|&)\" + name + \"=([^&]*)(&|$)\", \"i\");\r\n",
      "            var r = window.location.search.substr(1).match(reg);\r\n",
      "            if (r != null) return unescape(r[2]);\r\n",
      "            return null;\r\n",
      "        }\r\n",
      "        function isMobile() {\r\n",
      "            try {\r\n",
      "                if(getQueryString(\"has_jump_to_web\") == \"true\"){\r\n",
      "                    return false;//需要展示web，不做后面的wap端验证\r\n",
      "                }\r\n",
      "            } catch (err) { }\r\n",
      "\r\n",
      "            var ua = navigator.userAgent.toLowerCase();\r\n",
      "            var res = false;\r\n",
      "            var ipad = ua.match(/(ipad).*os\\s([\\d_]+)/),\r\n",
      "                isIphone = !ipad && ua.match(/(iphone)/),\r\n",
      "                isAndroid = ua.match(/(android)/) && ua.match(/(mobile)/),\r\n",
      "                isMobile = isIphone || isAndroid;\r\n",
      "            if (isMobile) {\r\n",
      "                res = true;\r\n",
      "            } else {\r\n",
      "                res = false;\r\n",
      "            }\r\n",
      "            return res;\r\n",
      "        }\r\n",
      "        if (isMobile()) {\r\n",
      "            location.href = __WAPURL;\r\n",
      "        }\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      " 2018年9月21日山东地区汽油柴油价格行情 _ 东方财富网\n"
     ]
    }
   ],
   "source": [
    "fullgastextinfo = requests.get(findurl)\n",
    "fullgastextinfo.encoding = 'utf-8'\n",
    "# 这里使用lxml作为BS4的解析引擎\n",
    "soup = BeautifulSoup(fullgastextinfo.text, features='lxml')\n",
    "print(soup.head.text, soup.title.text)\n",
    "sourcetxtfile = './output/sourcetxt/source_{0}.txt'.format(searchdate)\n",
    "# 将爬取的信息去空白行之后，存入本地文件\n",
    "with open(sourcetxtfile, 'w', encoding='utf-8') as f:\n",
    "    for index, line in enumerate(soup.text.split('\\n')):\n",
    "        if line.split():\n",
    "#             print(\"write to file\")\n",
    "#             print(\"count:\", index + 1, \"content:\", line)\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据之前的知识，查看具体油价信息的地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/2018-09-17 20_47_51.png' width='100%' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得XPATH示例：\n",
    "```\n",
    "//*[@id=\"ContentBody\"]/p[1]\n",
    "//*[@id=\"ContentBody\"]/p[2]\n",
    "...\n",
    "```\n",
    "既然确定文本一定在非常规矩的段落中，那就可以干活了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然知道文本在div中，且id为ContentBody，那么就可以直接定位div部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们再去找段落，用刚刚的结果，再通过find_all('p')就搞定了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>　　山东东营利津炼化今日<span id=\"Info.353\"><a class=\"infokey\" href=\"http://data.eastmoney.com/cjsj/yjtz/default.html\" target=\"_blank\">成品油</a></span>报价：国Ⅴ89#汽油8600元/吨，密度0.73；国五92#汽油8750元/吨，密度0.73；国五95#汽油8900元/吨，密度0.74；国五98#汽油9050元/吨，密度0.748；国六92#汽油8800元/吨，新出；国六95#汽油8950元/吨，新出；国六98#汽油9100元/吨，新出；国五0#车柴7750元/吨；国六0#车柴7800元/吨，密度0.836；国六-10#车柴无报价，密度0.836。</p>, <p>　　山东潍坊中化弘润今日成品油报价：国六92#汽油8850元/吨，密度0.72；国六95#汽油9050元/吨，密度0.72；国五0#普柴7950元/吨，新出；国五0#车柴8120元/吨，新出；常柴6350元/吨，新出；催柴出货停报。</p>]\n"
     ]
    }
   ],
   "source": [
    "# help(soup.find_all)\n",
    "print(soup.find('div', id='ContentBody').find_all('p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们接着再往下来~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意singlegasprovider.text的用法，其能够去除段落中的所有html标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "　　山东东营利津炼化今日成品油报价：国Ⅴ89#汽油8600元/吨，密度0.73；国五92#汽油8750元/吨，密度0.73；国五95#汽油8900元/吨，密度0.74；国五98#汽油9050元/吨，密度0.748；国六92#汽油8800元/吨，新出；国六95#汽油8950元/吨，新出；国六98#汽油9100元/吨，新出；国五0#车柴7750元/吨；国六0#车柴7800元/吨，密度0.836；国六-10#车柴无报价，密度0.836。\n",
      "　　山东潍坊中化弘润今日成品油报价：国六92#汽油8850元/吨，密度0.72；国六95#汽油9050元/吨，密度0.72；国五0#普柴7950元/吨，新出；国五0#车柴8120元/吨，新出；常柴6350元/吨，新出；催柴出货停报。\n"
     ]
    }
   ],
   "source": [
    "for singlegasprovider in soup.find('div', id='ContentBody').find_all('p'):\n",
    "    print(singlegasprovider.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讲真，我是期望把数据表格化的，目前来看有点乱，所以还需要加入正则方面的内容。<br>\n",
    "然后pandas就出场了，这里有些大材小用，但是用的顺手就选它了~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wwqq 油无报rwww ioopp ee\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "temp = r'wwqq；油无报rwww。，：ioopp；。。ee'\n",
    "temp = re.sub('(\\W)', ' ', temp)\n",
    "temp = re.sub('( ){2,}', ' ', temp)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国四93#汽油无报价 国四93#汽油\n"
     ]
    }
   ],
   "source": [
    "gasinfo = r'国四93#汽油无报价'\n",
    "pattern = re.compile(r'(.*)(无报价|无货)')\n",
    "gastype = pattern.search(gasinfo).group(1)\n",
    "print(pattern.search(gasinfo).group(0), gastype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后用正则硬刚："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>releasedate</th>\n",
       "      <th>provider</th>\n",
       "      <th>producttype</th>\n",
       "      <th>productprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国Ⅴ89#汽油</td>\n",
       "      <td>8600元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国五92#汽油</td>\n",
       "      <td>8750元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国五95#汽油</td>\n",
       "      <td>8900元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国五98#汽油</td>\n",
       "      <td>9050元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国六92#汽油</td>\n",
       "      <td>8800元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国六95#汽油</td>\n",
       "      <td>8950元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国六98#汽油</td>\n",
       "      <td>9100元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国五0#车柴</td>\n",
       "      <td>7750元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国六0#车柴</td>\n",
       "      <td>7800元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东东营利津炼化</td>\n",
       "      <td>国六-10#车柴</td>\n",
       "      <td>无报价</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东潍坊中化弘润</td>\n",
       "      <td>国六92#汽油</td>\n",
       "      <td>8850元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东潍坊中化弘润</td>\n",
       "      <td>国六95#汽油</td>\n",
       "      <td>9050元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东潍坊中化弘润</td>\n",
       "      <td>国五0#普柴</td>\n",
       "      <td>7950元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东潍坊中化弘润</td>\n",
       "      <td>国五0#车柴</td>\n",
       "      <td>8120元/吨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018年9月21日</td>\n",
       "      <td>山东潍坊中化弘润</td>\n",
       "      <td>常柴</td>\n",
       "      <td>6350元/吨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   releasedate  provider producttype productprice\n",
       "0   2018年9月21日  山东东营利津炼化     国Ⅴ89#汽油      8600元/吨\n",
       "1   2018年9月21日  山东东营利津炼化     国五92#汽油      8750元/吨\n",
       "2   2018年9月21日  山东东营利津炼化     国五95#汽油      8900元/吨\n",
       "3   2018年9月21日  山东东营利津炼化     国五98#汽油      9050元/吨\n",
       "4   2018年9月21日  山东东营利津炼化     国六92#汽油      8800元/吨\n",
       "5   2018年9月21日  山东东营利津炼化     国六95#汽油      8950元/吨\n",
       "6   2018年9月21日  山东东营利津炼化     国六98#汽油      9100元/吨\n",
       "7   2018年9月21日  山东东营利津炼化      国五0#车柴      7750元/吨\n",
       "8   2018年9月21日  山东东营利津炼化      国六0#车柴      7800元/吨\n",
       "9   2018年9月21日  山东东营利津炼化    国六-10#车柴          无报价\n",
       "10  2018年9月21日  山东潍坊中化弘润     国六92#汽油      8850元/吨\n",
       "11  2018年9月21日  山东潍坊中化弘润     国六95#汽油      9050元/吨\n",
       "12  2018年9月21日  山东潍坊中化弘润      国五0#普柴      7950元/吨\n",
       "13  2018年9月21日  山东潍坊中化弘润      国五0#车柴      8120元/吨\n",
       "14  2018年9月21日  山东潍坊中化弘润          常柴      6350元/吨"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfresult = pd.DataFrame(columns=('releasedate',\n",
    "                                 'provider',\n",
    "                                 'producttype',\n",
    "                                 'productprice'))\n",
    "dfindex = 0\n",
    "for singlegasprovider in soup.find('div', id='ContentBody').find_all('p'):\n",
    "    content = singlegasprovider.text\n",
    "    if (len(content) > 0 and \n",
    "       re.match(r'(.*)今日', content) is not None):\n",
    "        content = content.replace('。','；')\n",
    "        provider = re.match(r'(.*)今日', content).group(1)\n",
    "        pattern = re.compile(r'报价：(.*)')\n",
    "        gasinfo = pattern.search(content)\n",
    "        if gasinfo is not None:\n",
    "            gaslist = gasinfo.group(1).split(r'；')\n",
    "            for gas in gaslist:\n",
    "                gastypeprice = gas.split(r'，')\n",
    "                if ('无报价' in gastypeprice[0] or\n",
    "                   '无货' in gastypeprice[0]):\n",
    "                    pattern = re.compile(r'(.*)(无报价|无货)')\n",
    "                    gastype = pattern.search(gastypeprice[0]).group(1)\n",
    "                    gasprice = r'无报价'\n",
    "                else:\n",
    "                    pattern = re.compile(r'([1-9]\\d*元/吨)')\n",
    "                    if pattern.search(gastypeprice[0]) is None:\n",
    "                        continue\n",
    "                    gasprice = pattern.search(gastypeprice[0]).group(1)\n",
    "                    gastype = gastypeprice[0].replace(gasprice, '')\n",
    "                dfresult.loc[dfindex] = {'releasedate': searchdate.strip(),\n",
    "                                         'provider': provider.strip(),\n",
    "                                         'producttype': gastype.strip(),\n",
    "                                         'productprice': gasprice}\n",
    "                dfindex += 1\n",
    "display(dfresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后将数据存储到csv中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfresult.to_csv('./output/result_{0}.csv'.format(searchdate), encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:10:26.548580Z",
     "start_time": "2022-11-09T10:10:26.530044Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag, Comment, Doctype\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:12:06.505102Z",
     "start_time": "2022-11-09T10:12:06.424506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NavigableString in module bs4.element:\n",
      "\n",
      "class NavigableString(builtins.str, PageElement)\n",
      " |  NavigableString(value)\n",
      " |  \n",
      " |  A Python Unicode string that is part of a parse tree.\n",
      " |  \n",
      " |  When Beautiful Soup parses the markup <b>penguin</b>, it will\n",
      " |  create a NavigableString for the string \"penguin\".\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NavigableString\n",
      " |      builtins.str\n",
      " |      PageElement\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |      A copy of a NavigableString has the same contents and class\n",
      " |      as the original, but it is not connected to the parse tree.\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |      text.string gives you text. This is for backwards\n",
      " |      compatibility for Navigable*String, but for CData* it lets you\n",
      " |      get the string without the CData wrapper.\n",
      " |  \n",
      " |  __getnewargs__(self)\n",
      " |  \n",
      " |  output_ready(self, formatter='minimal')\n",
      " |      Run the string through the provided formatter.\n",
      " |      \n",
      " |      :param formatter: A Formatter object, or a string naming one of the standard formatters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, value)\n",
      " |      Create a new NavigableString.\n",
      " |      \n",
      " |      When unpickling a NavigableString, this method is called with\n",
      " |      the string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be\n",
      " |      passed in to the superclass's __new__ or the superclass won't know\n",
      " |      how to handle non-ASCII characters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  strings\n",
      " |      Yield all strings of certain classes, possibly stripping them.\n",
      " |      \n",
      " |      This makes it easy for NavigableString to implement methods\n",
      " |      like get_text() as conveniences, creating a consistent\n",
      " |      text-extraction API across all PageElements.\n",
      " |      \n",
      " |      :param strip: If True, all strings will be stripped before being\n",
      " |          yielded.\n",
      " |      \n",
      " |      :param types: A tuple of NavigableString subclasses. If this\n",
      " |          NavigableString isn't one of those subclasses, the\n",
      " |          sequence will be empty. By default, the subclasses\n",
      " |          considered are NavigableString and CData objects. That\n",
      " |          means no comments, processing instructions, etc.\n",
      " |      \n",
      " |      :yield: A sequence that either contains this string, or is empty.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  name\n",
      " |      Since a NavigableString is not a Tag, it has no .name.\n",
      " |      \n",
      " |      This property is implemented so that code like this doesn't crash\n",
      " |      when run on a mixture of Tag and NavigableString objects:\n",
      " |          [x.name for x in tag.children]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  PREFIX = ''\n",
      " |  \n",
      " |  SUFFIX = ''\n",
      " |  \n",
      " |  known_xml = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.str:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Return a formatted version of the string as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the string in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(self, /)\n",
      " |      Return a capitalized version of the string.\n",
      " |      \n",
      " |      More specifically, make the first character have upper case and the rest lower\n",
      " |      case.\n",
      " |  \n",
      " |  casefold(self, /)\n",
      " |      Return a version of the string suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(self, width, fillchar=' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Encode the string using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding in which to encode the string.\n",
      " |      errors\n",
      " |        The error handling scheme to use for encoding errors.\n",
      " |        The default is 'strict' meaning that encoding errors raise a\n",
      " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      " |        'xmlcharrefreplace' as well as any other name registered with\n",
      " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(self, /)\n",
      " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isalpha(self, /)\n",
      " |      Return True if the string is an alphabetic string, False otherwise.\n",
      " |      \n",
      " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isascii(self, /)\n",
      " |      Return True if all characters in the string are ASCII, False otherwise.\n",
      " |      \n",
      " |      ASCII characters have code points in the range U+0000-U+007F.\n",
      " |      Empty string is ASCII too.\n",
      " |  \n",
      " |  isdecimal(self, /)\n",
      " |      Return True if the string is a decimal string, False otherwise.\n",
      " |      \n",
      " |      A string is a decimal string if all characters in the string are decimal and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isdigit(self, /)\n",
      " |      Return True if the string is a digit string, False otherwise.\n",
      " |      \n",
      " |      A string is a digit string if all characters in the string are digits and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isidentifier(self, /)\n",
      " |      Return True if the string is a valid Python identifier, False otherwise.\n",
      " |      \n",
      " |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
      " |      such as \"def\" or \"class\".\n",
      " |  \n",
      " |  islower(self, /)\n",
      " |      Return True if the string is a lowercase string, False otherwise.\n",
      " |      \n",
      " |      A string is lowercase if all cased characters in the string are lowercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  isnumeric(self, /)\n",
      " |      Return True if the string is a numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is numeric if all characters in the string are numeric and there is at\n",
      " |      least one character in the string.\n",
      " |  \n",
      " |  isprintable(self, /)\n",
      " |      Return True if the string is printable, False otherwise.\n",
      " |      \n",
      " |      A string is printable if all of its characters are considered printable in\n",
      " |      repr() or if it is empty.\n",
      " |  \n",
      " |  isspace(self, /)\n",
      " |      Return True if the string is a whitespace string, False otherwise.\n",
      " |      \n",
      " |      A string is whitespace if all characters in the string are whitespace and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  istitle(self, /)\n",
      " |      Return True if the string is a title-cased string, False otherwise.\n",
      " |      \n",
      " |      In a title-cased string, upper- and title-case characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |  \n",
      " |  isupper(self, /)\n",
      " |      Return True if the string is an uppercase string, False otherwise.\n",
      " |      \n",
      " |      A string is uppercase if all cased characters in the string are uppercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  join(self, iterable, /)\n",
      " |      Concatenate any number of strings.\n",
      " |      \n",
      " |      The string whose method is called is inserted in between each given string.\n",
      " |      The result is returned as a new string.\n",
      " |      \n",
      " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      " |  \n",
      " |  ljust(self, width, fillchar=' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(self, /)\n",
      " |      Return a copy of the string converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string.  If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original string\n",
      " |      and two empty strings.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      " |      and the original string.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the string.\n",
      " |          None (the default value) means split according to any whitespace,\n",
      " |          and discard empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splits are done starting at the end of the string and working to the front.\n",
      " |  \n",
      " |  rstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the string.\n",
      " |        None (the default value) means split according to any whitespace,\n",
      " |        and discard empty strings from the result.\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the string, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading and trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(self, /)\n",
      " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      " |  \n",
      " |  title(self, /)\n",
      " |      Return a version of the string where each word is titlecased.\n",
      " |      \n",
      " |      More specifically, words start with uppercased characters and all remaining\n",
      " |      cased characters have lower case.\n",
      " |  \n",
      " |  translate(self, table, /)\n",
      " |      Replace each character in the string using the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a mapping of Unicode ordinals to\n",
      " |          Unicode ordinals, strings, or None.\n",
      " |      \n",
      " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      " |      dictionary or list.  If this operation raises LookupError, the character is\n",
      " |      left untouched.  Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(self, /)\n",
      " |      Return a copy of the string converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from builtins.str:\n",
      " |  \n",
      " |  maketrans(...)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from PageElement:\n",
      " |  \n",
      " |  append(self, tag)\n",
      " |      Appends the given PageElement to the contents of this one.\n",
      " |      \n",
      " |      :param tag: A PageElement.\n",
      " |  \n",
      " |  extend(self, tags)\n",
      " |      Appends the given PageElements to this one's contents.\n",
      " |      \n",
      " |      :param tags: A list of PageElements.\n",
      " |  \n",
      " |  extract(self, _self_index=None)\n",
      " |      Destructively rips this element out of the tree.\n",
      " |      \n",
      " |      :param _self_index: The location of this element in its parent's\n",
      " |         .contents, if known. Passing this in allows for a performance\n",
      " |         optimization.\n",
      " |      \n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  fetchNextSiblings = find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchPrevious = find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findAllNext = find_all_next(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findAllPrevious = find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findNext = find_next(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |  \n",
      " |  findNextSibling = find_next_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |  \n",
      " |  findNextSiblings = find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findParent = find_parent(self, name=None, attrs={}, **kwargs)\n",
      " |  \n",
      " |  findParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |  \n",
      " |  findPrevious = find_previous(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |  \n",
      " |  findPreviousSibling = find_previous_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |  \n",
      " |  findPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  find_all_next(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |      Find all PageElements that match the given criteria and appear\n",
      " |      later in the document than this PageElement.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet containing PageElements.\n",
      " |  \n",
      " |  find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |      Look backwards in the document from this PageElement and find all\n",
      " |      PageElements that match the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  find_next(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |      Find the first PageElement that matches the given criteria and\n",
      " |      appears later in the document than this PageElement.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_next_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |      Find the closest sibling to this PageElement that matches the\n",
      " |      given criteria and appears later in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the\n",
      " |      online documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |      Find all siblings of this PageElement that match the given criteria\n",
      " |      and appear later in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  find_parent(self, name=None, attrs={}, **kwargs)\n",
      " |      Find the closest parent of this PageElement that matches the given\n",
      " |      criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |      Find all parents of this PageElement that match the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |      Look backwards in the document from this PageElement and find the\n",
      " |      first PageElement that matches the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      " |      Returns the closest sibling to this PageElement that matches the\n",
      " |      given criteria and appears earlier in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      " |      Returns all siblings to this PageElement that match the\n",
      " |      given criteria and appear earlier in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param string: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  format_string(self, s, formatter)\n",
      " |      Format the given string using the given formatter.\n",
      " |      \n",
      " |      :param s: A string.\n",
      " |      :param formatter: A Formatter object, or a string naming one of the standard formatters.\n",
      " |  \n",
      " |  formatter_for_name(self, formatter)\n",
      " |      Look up or create a Formatter for the given identifier,\n",
      " |      if necessary.\n",
      " |      \n",
      " |      :param formatter: Can be a Formatter object (used as-is), a\n",
      " |          function (used as the entity substitution hook for an\n",
      " |          XMLFormatter or HTMLFormatter), or a string (used to look\n",
      " |          up an XMLFormatter or HTMLFormatter in the appropriate\n",
      " |          registry.\n",
      " |  \n",
      " |  getText = get_text(self, separator='', strip=False, types=<object object at 0x000001D2F80C5E40>)\n",
      " |  \n",
      " |  get_text(self, separator='', strip=False, types=<object object at 0x000001D2F80C5E40>)\n",
      " |      Get all child strings of this PageElement, concatenated using the\n",
      " |      given separator.\n",
      " |      \n",
      " |      :param separator: Strings will be concatenated using this separator.\n",
      " |      \n",
      " |      :param strip: If True, strings will be stripped before being\n",
      " |          concatenated.\n",
      " |      \n",
      " |      :param types: A tuple of NavigableString subclasses. Any\n",
      " |          strings of a subclass not found in this list will be\n",
      " |          ignored. Although there are exceptions, the default\n",
      " |          behavior in most cases is to consider only NavigableString\n",
      " |          and CData objects. That means no comments, processing\n",
      " |          instructions, etc.\n",
      " |      \n",
      " |      :return: A string.\n",
      " |  \n",
      " |  insert(self, position, new_child)\n",
      " |      Insert a new PageElement in the list of this PageElement's children.\n",
      " |      \n",
      " |      This works the same way as `list.insert`.\n",
      " |      \n",
      " |      :param position: The numeric position that should be occupied\n",
      " |         in `self.children` by the new PageElement. \n",
      " |      :param new_child: A PageElement.\n",
      " |  \n",
      " |  insert_after(self, *args)\n",
      " |      Makes the given element(s) the immediate successor of this one.\n",
      " |      \n",
      " |      The elements will have the same parent, and the given elements\n",
      " |      will be immediately after this one.\n",
      " |      \n",
      " |      :param args: One or more PageElements.\n",
      " |  \n",
      " |  insert_before(self, *args)\n",
      " |      Makes the given element(s) the immediate predecessor of this one.\n",
      " |      \n",
      " |      All the elements will have the same parent, and the given elements\n",
      " |      will be immediately before this one.\n",
      " |      \n",
      " |      :param args: One or more PageElements.\n",
      " |  \n",
      " |  nextGenerator(self)\n",
      " |      # Old non-property versions of the generators, for backwards\n",
      " |      # compatibility with BS3.\n",
      " |  \n",
      " |  nextSiblingGenerator(self)\n",
      " |  \n",
      " |  parentGenerator(self)\n",
      " |  \n",
      " |  previousGenerator(self)\n",
      " |  \n",
      " |  previousSiblingGenerator(self)\n",
      " |  \n",
      " |  replaceWith = replace_with(self, *args)\n",
      " |  \n",
      " |  replaceWithChildren = unwrap(self)\n",
      " |  \n",
      " |  replace_with(self, *args)\n",
      " |      Replace this PageElement with one or more PageElements, keeping the \n",
      " |      rest of the tree the same.\n",
      " |      \n",
      " |      :param args: One or more PageElements.\n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  replace_with_children = unwrap(self)\n",
      " |  \n",
      " |  setup(self, parent=None, previous_element=None, next_element=None, previous_sibling=None, next_sibling=None)\n",
      " |      Sets up the initial relations between this element and\n",
      " |      other elements.\n",
      " |      \n",
      " |      :param parent: The parent of this element.\n",
      " |      \n",
      " |      :param previous_element: The element parsed immediately before\n",
      " |          this one.\n",
      " |      \n",
      " |      :param next_element: The element parsed immediately before\n",
      " |          this one.\n",
      " |      \n",
      " |      :param previous_sibling: The most recently encountered element\n",
      " |          on the same level of the parse tree as this one.\n",
      " |      \n",
      " |      :param previous_sibling: The next element to be encountered\n",
      " |          on the same level of the parse tree as this one.\n",
      " |  \n",
      " |  unwrap(self)\n",
      " |      Replace this PageElement with its contents.\n",
      " |      \n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  wrap(self, wrap_inside)\n",
      " |      Wrap this PageElement inside another one.\n",
      " |      \n",
      " |      :param wrap_inside: A PageElement.\n",
      " |      :return: `wrap_inside`, occupying the position in the tree that used\n",
      " |         to be occupied by `self`, and with `self` inside it.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from PageElement:\n",
      " |  \n",
      " |  decomposed\n",
      " |      Check whether a PageElement has been decomposed.\n",
      " |      \n",
      " |      :rtype: bool\n",
      " |  \n",
      " |  next\n",
      " |      The PageElement, if any, that was parsed just after this one.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  next_elements\n",
      " |      All PageElements that were parsed after this one.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  next_siblings\n",
      " |      All PageElements that are siblings of this one but were parsed\n",
      " |      later.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  parents\n",
      " |      All PageElements that are parents of this PageElement.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  previous\n",
      " |      The PageElement, if any, that was parsed just before this one.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  previous_elements\n",
      " |      All PageElements that were parsed before this one.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  previous_siblings\n",
      " |      All PageElements that are siblings of this one but were parsed\n",
      " |      earlier.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  stripped_strings\n",
      " |      Yield all strings in this PageElement, stripping them first.\n",
      " |      \n",
      " |      :yield: A sequence of stripped strings.\n",
      " |  \n",
      " |  text\n",
      " |      Get all child strings of this PageElement, concatenated using the\n",
      " |      given separator.\n",
      " |      \n",
      " |      :param separator: Strings will be concatenated using this separator.\n",
      " |      \n",
      " |      :param strip: If True, strings will be stripped before being\n",
      " |          concatenated.\n",
      " |      \n",
      " |      :param types: A tuple of NavigableString subclasses. Any\n",
      " |          strings of a subclass not found in this list will be\n",
      " |          ignored. Although there are exceptions, the default\n",
      " |          behavior in most cases is to consider only NavigableString\n",
      " |          and CData objects. That means no comments, processing\n",
      " |          instructions, etc.\n",
      " |      \n",
      " |      :return: A string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from PageElement:\n",
      " |  \n",
      " |  nextSibling\n",
      " |  \n",
      " |  previousSibling\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from PageElement:\n",
      " |  \n",
      " |  default = <object object>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NavigableString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:01:04.355001Z",
     "start_time": "2022-11-09T10:01:04.335197Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_html(pathfile, return_html_obj=True):\n",
    "    cond = pathfile.endswith('htm') or pathfile.endswith('html')\n",
    "    assert cond, \"file must end with .htm or .html\\n{}\".format(pathfile)\n",
    "    assert os.path.exists(pathfile), \"file does not exist\\n{}\".format(pathfile)\n",
    "    with open(pathfile, 'r', encoding='utf-8', errors='ignore') as rf:\n",
    "        html_txt = rf.read()\n",
    "    if return_html_obj:\n",
    "        try:\n",
    "            ans = BeautifulSoup(html_txt, 'lxml')\n",
    "        except Exception as e:\n",
    "            ans = BeautifulSoup(html_txt, 'html.parser')\n",
    "    else:\n",
    "        ans = html_txt\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:01:05.035312Z",
     "start_time": "2022-11-09T10:01:05.016474Z"
    }
   },
   "outputs": [],
   "source": [
    "path_file = r'./html/332240067_PE.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:08:08.171725Z",
     "start_time": "2022-11-09T10:08:07.656182Z"
    }
   },
   "outputs": [],
   "source": [
    "html_obj = load_html(pathfile=path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:06:57.703475Z",
     "start_time": "2022-11-09T10:06:57.612944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data_point': 'ActualManagtFee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.60 '},\n",
       " {'data_point': 'ActualManagtFee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.60 '},\n",
       " {'data_point': 'Actual12B1Fee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.25 '},\n",
       " {'data_point': 'Actual12B1Fee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.00 '},\n",
       " {'data_point': 'ProsGrossExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 1.21 '},\n",
       " {'data_point': 'ProsGrossExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.96 '},\n",
       " {'data_point': 'ExpWaiverAmount',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.01% '},\n",
       " {'data_point': 'ExpWaiverAmount',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.01% '},\n",
       " {'data_point': 'ProsNetExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 1.20 '},\n",
       " {'data_point': 'ProsNetExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.95 '},\n",
       " {'data_point': 'ExpProjectionUnit',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': '',\n",
       "  'text': ' $10,000 '},\n",
       " {'data_point': 'ExpProjection1Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 122 '},\n",
       " {'data_point': 'ExpProjection3Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 383 '},\n",
       " {'data_point': 'ExpProjection5Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 664 '},\n",
       " {'data_point': 'ExpProjection10Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 1,465 '},\n",
       " {'data_point': 'ExpProjection1Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 97 '},\n",
       " {'data_point': 'ExpProjection3Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 305 '},\n",
       " {'data_point': 'ExpProjection5Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 530 '},\n",
       " {'data_point': 'ExpProjection10Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 1,177 '},\n",
       " {'data_point': 'ActualManagtFee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.60 '},\n",
       " {'data_point': 'ActualManagtFee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.60 '},\n",
       " {'data_point': 'Actual12B1Fee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.25 '},\n",
       " {'data_point': 'Actual12B1Fee',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.00 '},\n",
       " {'data_point': 'AcquiredExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.27 '},\n",
       " {'data_point': 'AcquiredExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.27 '},\n",
       " {'data_point': 'ProsGrossExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 2.04 '},\n",
       " {'data_point': 'ProsGrossExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 1.76 '},\n",
       " {'data_point': 'ExpWaiverAmount',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 0.94% '},\n",
       " {'data_point': 'ExpWaiverAmount',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.91% '},\n",
       " {'data_point': 'ProsNetExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 1.10 '},\n",
       " {'data_point': 'ProsNetExpense',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 0.85 '},\n",
       " {'data_point': 'ExpProjectionUnit',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': '',\n",
       "  'text': ' $10,000 '},\n",
       " {'data_point': 'ExpProjection1Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 112 '},\n",
       " {'data_point': 'ExpProjection3Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 549 '},\n",
       " {'data_point': 'ExpProjection5Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 1,011 '},\n",
       " {'data_point': 'ExpProjection10Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class I',\n",
       "  'text': ' 2,294 '},\n",
       " {'data_point': 'ExpProjection1Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 87 '},\n",
       " {'data_point': 'ExpProjection3Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 465 '},\n",
       " {'data_point': 'ExpProjection5Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 869 '},\n",
       " {'data_point': 'ExpProjection10Year',\n",
       "  'data-type': 'PE Fee',\n",
       "  'shareclass': 'Class II',\n",
       "  'text': ' 1,998 '}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_span_list = html_obj.find_all('span', attrs={'annotation_id': True})\n",
    "# print(annotation_span_list)\n",
    "data_list = []\n",
    "\"\"\"\n",
    "<span annotation_id=\"8d79333c-a27c-11eb-93f9-0242ac110002\" \n",
    "class=\"pred_tag_background\" data=\"ProsGrossExpense\" \n",
    "data-p_datapoint=\"ProsGrossExpense\" \n",
    "data-p_shareclass=\"Class I\" data-type=\"PE Fee\" title=\"ProsGrossExpense\" valid_i2k=\"True\"> 1.21 </span>\n",
    "\"\"\"\n",
    "for annotation in annotation_span_list:\n",
    "    data = {}\n",
    "    data['data_point'] = annotation.get('data-p_datapoint', '')\n",
    "    data['data-type'] = annotation.get('data-type', '')\n",
    "    data['shareclass'] = annotation.get('data-p_shareclass', '')\n",
    "    data['text'] = annotation.text\n",
    "    data_list.append(data)\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:07:07.413336Z",
     "start_time": "2022-11-09T10:07:07.400450Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:07:11.171474Z",
     "start_time": "2022-11-09T10:07:11.118820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_point</th>\n",
       "      <th>data-type</th>\n",
       "      <th>shareclass</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ActualManagtFee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ActualManagtFee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actual12B1Fee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actual12B1Fee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ProsGrossExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ProsGrossExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExpWaiverAmount</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExpWaiverAmount</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ProsNetExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ProsNetExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExpProjectionUnit</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td></td>\n",
       "      <td>$10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExpProjection1Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExpProjection3Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExpProjection5Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExpProjection10Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>1,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExpProjection1Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExpProjection3Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExpProjection5Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExpProjection10Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>1,177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ActualManagtFee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ActualManagtFee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Actual12B1Fee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Actual12B1Fee</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AcquiredExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AcquiredExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ProsGrossExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ProsGrossExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ExpWaiverAmount</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>0.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ExpWaiverAmount</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ProsNetExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ProsNetExpense</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ExpProjectionUnit</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td></td>\n",
       "      <td>$10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ExpProjection1Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ExpProjection3Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ExpProjection5Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>1,011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ExpProjection10Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class I</td>\n",
       "      <td>2,294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExpProjection1Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExpProjection3Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ExpProjection5Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ExpProjection10Year</td>\n",
       "      <td>PE Fee</td>\n",
       "      <td>Class II</td>\n",
       "      <td>1,998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             data_point data-type shareclass       text\n",
       "0       ActualManagtFee    PE Fee    Class I      0.60 \n",
       "1       ActualManagtFee    PE Fee   Class II      0.60 \n",
       "2         Actual12B1Fee    PE Fee    Class I      0.25 \n",
       "3         Actual12B1Fee    PE Fee   Class II      0.00 \n",
       "4      ProsGrossExpense    PE Fee    Class I      1.21 \n",
       "5      ProsGrossExpense    PE Fee   Class II      0.96 \n",
       "6       ExpWaiverAmount    PE Fee    Class I     0.01% \n",
       "7       ExpWaiverAmount    PE Fee   Class II     0.01% \n",
       "8        ProsNetExpense    PE Fee    Class I      1.20 \n",
       "9        ProsNetExpense    PE Fee   Class II      0.95 \n",
       "10    ExpProjectionUnit    PE Fee              $10,000 \n",
       "11   ExpProjection1Year    PE Fee    Class I       122 \n",
       "12   ExpProjection3Year    PE Fee    Class I       383 \n",
       "13   ExpProjection5Year    PE Fee    Class I       664 \n",
       "14  ExpProjection10Year    PE Fee    Class I     1,465 \n",
       "15   ExpProjection1Year    PE Fee   Class II        97 \n",
       "16   ExpProjection3Year    PE Fee   Class II       305 \n",
       "17   ExpProjection5Year    PE Fee   Class II       530 \n",
       "18  ExpProjection10Year    PE Fee   Class II     1,177 \n",
       "19      ActualManagtFee    PE Fee    Class I      0.60 \n",
       "20      ActualManagtFee    PE Fee   Class II      0.60 \n",
       "21        Actual12B1Fee    PE Fee    Class I      0.25 \n",
       "22        Actual12B1Fee    PE Fee   Class II      0.00 \n",
       "23      AcquiredExpense    PE Fee    Class I      0.27 \n",
       "24      AcquiredExpense    PE Fee   Class II      0.27 \n",
       "25     ProsGrossExpense    PE Fee    Class I      2.04 \n",
       "26     ProsGrossExpense    PE Fee   Class II      1.76 \n",
       "27      ExpWaiverAmount    PE Fee    Class I     0.94% \n",
       "28      ExpWaiverAmount    PE Fee   Class II     0.91% \n",
       "29       ProsNetExpense    PE Fee    Class I      1.10 \n",
       "30       ProsNetExpense    PE Fee   Class II      0.85 \n",
       "31    ExpProjectionUnit    PE Fee              $10,000 \n",
       "32   ExpProjection1Year    PE Fee    Class I       112 \n",
       "33   ExpProjection3Year    PE Fee    Class I       549 \n",
       "34   ExpProjection5Year    PE Fee    Class I     1,011 \n",
       "35  ExpProjection10Year    PE Fee    Class I     2,294 \n",
       "36   ExpProjection1Year    PE Fee   Class II        87 \n",
       "37   ExpProjection3Year    PE Fee   Class II       465 \n",
       "38   ExpProjection5Year    PE Fee   Class II       869 \n",
       "39  ExpProjection10Year    PE Fee   Class II     1,998 "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
